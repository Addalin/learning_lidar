{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fast_funcs not available\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import learning_lidar.utils.global_settings as gs\n",
    "import learning_lidar.utils.vis_utils as vis_utils\n",
    "import pandas as pd\n",
    "import learning_lidar.preprocessing.preprocessing as prep\n",
    "import learning_lidar.preprocessing.preprocessing_utils as prep_utils\n",
    "from learning_lidar.generation.daily_signals_generations_utils import  calc_poiss_measurement,calc_range_corr_measurement\n",
    "import learning_lidar.generation.generation_utils as gen_utils\n",
    "import learning_lidar.dataseting.dataseting as dataseting\n",
    "import learning_lidar.utils.xr_utils as xr_utils\n",
    "import xarray as xr\n",
    "vis_utils.set_visualization_settings()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Imports\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Set parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "'C:\\\\Users\\\\addalin\\\\Dropbox\\\\Lidar\\\\lidar_learning\\\\data'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_name = 'haifa'\n",
    "station = gs.Station(station_name)\n",
    "wavelengths = gs.LAMBDA_nm().get_elastic()\n",
    "\n",
    "main_folder = os.path.dirname(os.path.abspath(os.path.curdir))\n",
    "data_folder = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(os.path.curdir))), 'data')\n",
    "data_folder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Calculate poisson on \"clear\" signals, without background, for the given period.\n",
    "Adding range corrected with applies poisson noise to signal database\n",
    "# TODO: ADD this to generation.py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "start_date = datetime(2017, 9, 1)\n",
    "end_date = datetime(2017, 10, 31)\n",
    "dates = pd.date_range(start_date,end_date,freq='D')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "CALC_STATS=False\n",
    "if CALC_STATS:\n",
    "    base_folder = station.gen_signal_dataset\n",
    "    paths = [os.path.join(prep.get_month_folder_name(base_folder, dt),\n",
    "     gen_utils.get_gen_dataset_file_name(station, dt, data_source='signal')) for dt in dates]\n",
    "    mean = np.zeros(3)\n",
    "    std = np.zeros(3)\n",
    "    norm_scale = 1 / len(dates)\n",
    "\n",
    "    for cur_date,nc_path in zip(dates,paths):\n",
    "        signal_ds = prep.load_dataset(nc_path)\n",
    "        signal_ds\n",
    "        pn_ds = calc_poiss_measurement(station, cur_date, signal_ds.p)  # lidar measurement: pn ~Poiss(mu_p)\n",
    "        pr2n_ds = calc_range_corr_measurement(station, cur_date, pn_ds, signal_ds.r2) # range corrected measurement: pr2n = pn * r^2\n",
    "        pr2n_ds.attrs['info']+=' - w.o. background'\n",
    "        mean += pr2n_ds.mean(dim={'Height', 'Time'}).values\n",
    "        std += pr2n_ds.std(dim={'Height', 'Time'}).values\n",
    "        signal_ds = signal_ds.assign(range_corr_p =pr2n_ds)\n",
    "        gen_utils.save_generated_dataset(station, signal_ds,\n",
    "                                         data_source='signal',\n",
    "                                         save_mode='both',\n",
    "                                         profiles=['range_corr_p'])\n",
    "\n",
    "    mean *= norm_scale\n",
    "    std *= norm_scale"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Statistics for a period of the dataset\n",
    "> Loading the statistics database created in dataseting.py\n",
    "# TODO: ADD this to statistics calculation\n",
    "# TODO: ADD `range_corr_p` as  column to dataseting.py (gen_csv)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "   wavelength  p_signal_mean  p_signal_std  p_signal_min  p_signal_max  \\\n0       355.0      88.280901    812.655000      0.003964  21699.117680   \n1       532.0      94.206550    844.996252      0.008764  23194.884770   \n2      1064.0      25.641477    223.603415      0.001039   6651.830518   \n3         NaN            NaN           NaN           NaN           NaN   \n4         NaN            NaN           NaN           NaN           NaN   \n5         NaN            NaN           NaN           NaN           NaN   \n6         NaN            NaN           NaN           NaN           NaN   \n\n   range_corr_signal_mean  range_corr_signal_std  range_corr_signal_min  \\\n0               15.549797              24.042348               0.936831   \n1               22.552368              28.921022               2.071057   \n2                7.308976               9.713228               0.245562   \n3                     NaN                    NaN                    NaN   \n4                     NaN                    NaN                    NaN   \n5                     NaN                    NaN                    NaN   \n6                     NaN                    NaN                    NaN   \n\n   range_corr_signal_max  range_corr_p_signal_mean  ...        LC_min  \\\n0             134.568434                 15.533479  ...   9648.912511   \n1             145.640789                 22.529013  ...  29265.571770   \n2              47.037022                  7.304823  ...  22457.129270   \n3                    NaN                       NaN  ...           NaN   \n4                    NaN                       NaN  ...           NaN   \n5                    NaN                       NaN  ...           NaN   \n6                    NaN                       NaN  ...           NaN   \n\n        LC_max  p_bg_r2_bg_mean  p_bg_r2_bg_std  p_bg_r2_bg_min  \\\n0  12252.52209        11.142602       10.655540        0.000423   \n1  37062.94491        28.980261       27.025179        0.001372   \n2  28573.14919         2.017860        2.238724        0.000007   \n3          NaN              NaN             NaN             NaN   \n4          NaN              NaN             NaN             NaN   \n5          NaN              NaN             NaN             NaN   \n6          NaN              NaN             NaN             NaN   \n\n   p_bg_r2_bg_max  p_bg_r2_bg_mean.1  p_bg_r2_bg_std.1  p_bg_r2_bg_min.1  \\\n0       51.882701          11.142602         10.655540          0.000423   \n1      122.899301          28.980261         27.025179          0.001372   \n2       13.191458           2.017860          2.238724          0.000007   \n3             NaN                NaN               NaN               NaN   \n4             NaN                NaN               NaN               NaN   \n5             NaN                NaN               NaN               NaN   \n6             NaN                NaN               NaN               NaN   \n\n   p_bg_r2_bg_max.1  \n0         51.882701  \n1        122.899301  \n2         13.191458  \n3               NaN  \n4               NaN  \n5               NaN  \n6               NaN  \n\n[7 rows x 37 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>wavelength</th>\n      <th>p_signal_mean</th>\n      <th>p_signal_std</th>\n      <th>p_signal_min</th>\n      <th>p_signal_max</th>\n      <th>range_corr_signal_mean</th>\n      <th>range_corr_signal_std</th>\n      <th>range_corr_signal_min</th>\n      <th>range_corr_signal_max</th>\n      <th>range_corr_p_signal_mean</th>\n      <th>...</th>\n      <th>LC_min</th>\n      <th>LC_max</th>\n      <th>p_bg_r2_bg_mean</th>\n      <th>p_bg_r2_bg_std</th>\n      <th>p_bg_r2_bg_min</th>\n      <th>p_bg_r2_bg_max</th>\n      <th>p_bg_r2_bg_mean.1</th>\n      <th>p_bg_r2_bg_std.1</th>\n      <th>p_bg_r2_bg_min.1</th>\n      <th>p_bg_r2_bg_max.1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>355.0</td>\n      <td>88.280901</td>\n      <td>812.655000</td>\n      <td>0.003964</td>\n      <td>21699.117680</td>\n      <td>15.549797</td>\n      <td>24.042348</td>\n      <td>0.936831</td>\n      <td>134.568434</td>\n      <td>15.533479</td>\n      <td>...</td>\n      <td>9648.912511</td>\n      <td>12252.52209</td>\n      <td>11.142602</td>\n      <td>10.655540</td>\n      <td>0.000423</td>\n      <td>51.882701</td>\n      <td>11.142602</td>\n      <td>10.655540</td>\n      <td>0.000423</td>\n      <td>51.882701</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>532.0</td>\n      <td>94.206550</td>\n      <td>844.996252</td>\n      <td>0.008764</td>\n      <td>23194.884770</td>\n      <td>22.552368</td>\n      <td>28.921022</td>\n      <td>2.071057</td>\n      <td>145.640789</td>\n      <td>22.529013</td>\n      <td>...</td>\n      <td>29265.571770</td>\n      <td>37062.94491</td>\n      <td>28.980261</td>\n      <td>27.025179</td>\n      <td>0.001372</td>\n      <td>122.899301</td>\n      <td>28.980261</td>\n      <td>27.025179</td>\n      <td>0.001372</td>\n      <td>122.899301</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1064.0</td>\n      <td>25.641477</td>\n      <td>223.603415</td>\n      <td>0.001039</td>\n      <td>6651.830518</td>\n      <td>7.308976</td>\n      <td>9.713228</td>\n      <td>0.245562</td>\n      <td>47.037022</td>\n      <td>7.304823</td>\n      <td>...</td>\n      <td>22457.129270</td>\n      <td>28573.14919</td>\n      <td>2.017860</td>\n      <td>2.238724</td>\n      <td>0.000007</td>\n      <td>13.191458</td>\n      <td>2.017860</td>\n      <td>2.238724</td>\n      <td>0.000007</td>\n      <td>13.191458</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>7 rows × 37 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_fname = f\"stats_gen_{station.name}_{start_date.strftime('%Y-%m-%d')}_{end_date.strftime('%Y-%m-%d')}.csv\"\n",
    "csv_stats_path = os.path.join(data_folder, stats_fname)\n",
    "df_stats = pd.read_csv(csv_stats_path)\n",
    "df_stats"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "if CALC_STATS:\n",
    "    df_stats['range_corr_p_mean'] = mean\n",
    "    df_stats['range_corr_p_std'] = std\n",
    "    df_stats\n",
    "    df_stats.to_csv(csv_stats_path,index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Split files per time for each file in the database per sample time\n",
    "# TODO: move this to a new function prepare_generated_samples() after calling to create_generated_dataset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "CREATE_SAMPLES = False\n",
    "if CREATE_SAMPLES:\n",
    "    dataseting.prepare_generated_samples(station,start_date,end_date)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Update the current train and test datasets according to new paths in the generated dataset\n",
    "> such that the keys are not changed."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\addalin\\\\Dropbox\\\\Lidar\\\\lidar_learning\\\\data\\\\dataset_gen_haifa_2017-04-01_2017-10-31.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [19]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      4\u001B[0m csv_gen_test_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(data_folder,\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mgen_base_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_test.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      5\u001B[0m csv_gen_path, csv_gen_train_path,csv_gen_test_path\n\u001B[1;32m----> 7\u001B[0m df_gen \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcsv_gen_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m df_gen_train \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(csv_gen_train_path)\n\u001B[0;32m      9\u001B[0m df_gen_test \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(csv_gen_test_path)\n",
      "File \u001B[1;32m~\\.conda\\envs\\lidar_local_new\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    305\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[0;32m    306\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    307\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39marguments),\n\u001B[0;32m    308\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[0;32m    309\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mstacklevel,\n\u001B[0;32m    310\u001B[0m     )\n\u001B[1;32m--> 311\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\lidar_local_new\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    665\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m    666\u001B[0m     dialect,\n\u001B[0;32m    667\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    676\u001B[0m     defaults\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelimiter\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[0;32m    677\u001B[0m )\n\u001B[0;32m    678\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m--> 680\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\lidar_local_new\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    572\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    574\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[1;32m--> 575\u001B[0m parser \u001B[38;5;241m=\u001B[39m TextFileReader(filepath_or_buffer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    577\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[0;32m    578\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[1;32m~\\.conda\\envs\\lidar_local_new\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m    930\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    932\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 933\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\lidar_local_new\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1213\u001B[0m     mode \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1214\u001B[0m \u001B[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001B[39;00m\n\u001B[0;32m   1215\u001B[0m \u001B[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001B[39;00m\n\u001B[0;32m   1216\u001B[0m \u001B[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001B[39;00m\n\u001B[1;32m-> 1217\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[call-overload]\u001B[39;49;00m\n\u001B[0;32m   1218\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1219\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1220\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1221\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1222\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1223\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1224\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1225\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1226\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1227\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1228\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[1;32m~\\.conda\\envs\\lidar_local_new\\lib\\site-packages\\pandas\\io\\common.py:789\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    784\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    785\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[0;32m    786\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[0;32m    787\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[0;32m    788\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[1;32m--> 789\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    790\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    791\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    792\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    793\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    794\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    795\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    796\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    797\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[0;32m    798\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\addalin\\\\Dropbox\\\\Lidar\\\\lidar_learning\\\\data\\\\dataset_gen_haifa_2017-04-01_2017-10-31.csv'"
     ]
    }
   ],
   "source": [
    "gen_base_name = f\"dataset_gen_{station_name}_{start_date.strftime('%Y-%m-%d')}_{end_date.strftime('%Y-%m-%d')}\"\n",
    "csv_gen_path = os.path.join(data_folder,f\"{gen_base_name}.csv\")\n",
    "csv_gen_train_path = os.path.join(data_folder,f\"{gen_base_name}_train.csv\")\n",
    "csv_gen_test_path = os.path.join(data_folder,f\"{gen_base_name}_test.csv\")\n",
    "csv_gen_path, csv_gen_train_path,csv_gen_test_path\n",
    "\n",
    "df_gen = pd.read_csv(csv_gen_path)\n",
    "df_gen_train = pd.read_csv(csv_gen_train_path)\n",
    "df_gen_test = pd.read_csv(csv_gen_test_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# update p_bg with r2 multiplication\n",
    "> such that the keys are not changed.\n",
    "> TODO: If this improves the learning stage add it to the generation process and in dataseting proccess (including stats calculations)\n",
    "> TODO: it is better to use save_dataset2timesplits() in dataseting.py when doing time splis.\n",
    ">"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "CREATE_PBG_R2 =True\n",
    "df_gen['date'] = pd.to_datetime(df_gen['date'])\n",
    "grps_days = df_gen.groupby('date').groups\n",
    "mean = np.zeros(3)\n",
    "std = np.zeros(3)\n",
    "min = np.zeros(3)\n",
    "max = np.zeros(3)\n",
    "for day_dt, inds in grps_days.items():\n",
    "    wavelengths_grps =  df_gen.iloc[inds].groupby('wavelength').groups\n",
    "    tslices = dataseting.get_time_splits(station, day_dt, day_dt, '30min')\n",
    "    norm_scale = 1/(len(grps_days)*len(tslices))\n",
    "    r2_ds = prep_utils.calc_r2_da(station,day_dt)\n",
    "    for ind,tslice in enumerate(tslices):\n",
    "        for ind_wav,wavelength in enumerate(wavelengths_grps):\n",
    "            ind_gen = wavelengths_grps[wavelength][ind]\n",
    "            path = df_gen.iloc[ind_gen]['bg_path']\n",
    "            path = path.replace('E:','D:')\n",
    "            bg_ds = prep.load_dataset(path)\n",
    "            if CREATE_PBG_R2:\n",
    "                hslice = slice (bg_ds.Height[0].values,bg_ds.Height[-1].values )\n",
    "                r2_ds_slice = r2_ds.sel(Height = hslice, Time =tslice, Wavelength = wavelength)\n",
    "                p_bg_r2 = xr.apply_ufunc(lambda p,r2 : p*r2,bg_ds.p_bg, r2_ds_slice, keep_attrs=True).\\\n",
    "                    assign_attrs({'long_name':r'$<p_{\\rm bg}>$'+ r'$\\cdot r^2$',\n",
    "                               'units':r'$\\rm photons \\cdot km^2$','info':'Daily averaged background signal - range corrected'})\n",
    "                bg_ds = bg_ds.assign(p_bg_r2=p_bg_r2)\n",
    "                xr_utils.save_dataset(dataset=bg_ds, nc_path=path)\n",
    "\n",
    "            # update stats values:\n",
    "            mean[ind_wav]+= norm_scale * bg_ds.p_bg_r2.mean(dim={'Height', 'Time'}).values\n",
    "            std[ind_wav]+= norm_scale * bg_ds.p_bg_r2.std(dim={'Height', 'Time'}).values\n",
    "            min[ind_wav]+= norm_scale * bg_ds.p_bg_r2.min(dim={'Height', 'Time'}).values\n",
    "            max[ind_wav]+= norm_scale * bg_ds.p_bg_r2.max(dim={'Height', 'Time'}).values\n",
    "cols = ['p_bg_r2_bg_mean','p_bg_r2_bg_std','p_bg_r2_bg_min','p_bg_r2_bg_max']\n",
    "df_stats_p_pg = pd.DataFrame(data=[mean,std,min,max], index=cols).T\n",
    "new_df_stats = pd.concat([df_stats,df_stats_p_pg],axis=1)\n",
    "new_df_stats.to_csv(csv_stats_path,index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "new_df_stats.to_csv(csv_stats_path,index=False)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-env-.conda-lidar_local_new-py",
   "language": "python",
   "display_name": "Python [conda env:.conda-lidar_local_new] *"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}