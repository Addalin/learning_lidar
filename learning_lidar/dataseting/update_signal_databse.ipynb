{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import learning_lidar.utils.global_settings as gs\n",
    "import pandas as pd\n",
    "import learning_lidar.preprocessing.preprocessing as prep\n",
    "%matplotlib inline\n",
    "from learning_lidar.generation.daily_signals_generations_utils import  calc_poiss_measurement,calc_range_corr_measurement,calc_r2_ds\n",
    "import learning_lidar.generation.generation_utils as gen_utils\n",
    "import learning_lidar.dataseting.dataseting as dataseting\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "gs.set_visualization_settings()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Imports\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Set parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "'C:\\\\Users\\\\addalin\\\\Dropbox\\\\Lidar\\\\lidar_learning\\\\data'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_name = 'haifa'\n",
    "station = gs.Station(station_name)\n",
    "wavelengths = gs.LAMBDA_nm().get_elastic()\n",
    "\n",
    "main_folder = os.path.dirname(os.path.abspath(os.path.curdir))\n",
    "data_folder = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(os.path.curdir))), 'data')\n",
    "data_folder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Calculate poisson on \"clear\" signals, without background, for the given period.\n",
    "Adding range corrected with applies poisson noise to signal database\n",
    "# TODO: ADD this to generation.py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "start_date = datetime(2017, 9, 1)\n",
    "end_date = datetime(2017, 10, 31)\n",
    "dates = pd.date_range(start_date,end_date,freq='D')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "CALC_STATS=False\n",
    "if CALC_STATS:\n",
    "    base_folder = station.gen_signal_dataset\n",
    "    paths = [os.path.join(prep.get_month_folder_name(base_folder, dt),\n",
    "     gen_utils.get_gen_dataset_file_name(station, dt, data_source='signal')) for dt in dates]\n",
    "    mean = np.zeros(3)\n",
    "    std = np.zeros(3)\n",
    "    norm_scale = 1 / len(dates)\n",
    "\n",
    "    for cur_date,nc_path in zip(dates,paths):\n",
    "        signal_ds = prep.load_dataset(nc_path)\n",
    "        signal_ds\n",
    "        pn_ds = calc_poiss_measurement(station, cur_date, signal_ds.p)  # lidar measurement: pn ~Poiss(mu_p)\n",
    "        pr2n_ds = calc_range_corr_measurement(station, cur_date, pn_ds, signal_ds.r2) # range corrected measurement: pr2n = pn * r^2\n",
    "        pr2n_ds.attrs['info']+=' - w.o. background'\n",
    "        mean += pr2n_ds.mean(dim={'Height', 'Time'}).values\n",
    "        std += pr2n_ds.std(dim={'Height', 'Time'}).values\n",
    "        signal_ds = signal_ds.assign(range_corr_p =pr2n_ds)\n",
    "        gen_utils.save_generated_dataset(station, signal_ds,\n",
    "                                         data_source='signal',\n",
    "                                         save_mode='both',\n",
    "                                         profiles=['range_corr_p'])\n",
    "\n",
    "    mean *= norm_scale\n",
    "    std *= norm_scale"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Statistics for a period of the dataset\n",
    "> Loading the statistics database created in dataseting.py\n",
    "# TODO: ADD this to statistics calculation\n",
    "# TODO: ADD `range_corr_p` as  column to dataseting.py (gen_csv)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "   wavelength  p_signal_mean  p_signal_std  p_signal_min  p_signal_max  \\\n0         355      88.280901    812.655000      0.003964  21699.117677   \n1         532      94.206550    844.996252      0.008764  23194.884773   \n2        1064      25.641477    223.603415      0.001039   6651.830518   \n\n   range_corr_signal_mean  range_corr_signal_std  range_corr_signal_min  \\\n0               15.549797              24.042348               0.936831   \n1               22.552368              28.921022               2.071057   \n2                7.308976               9.713228               0.245562   \n\n   range_corr_signal_max  range_corr_p_signal_mean  ...  attbsc_molecular_min  \\\n0             134.568434                 15.533479  ...              0.000491   \n1             145.640789                 22.529013  ...              0.000210   \n2              47.037022                  7.304823  ...              0.000015   \n\n   attbsc_molecular_max  p_bg_bg_mean  p_bg_bg_std  p_bg_bg_min  p_bg_bg_max  \\\n0              0.007664      0.136932     0.152953     0.000403     0.595537   \n1              0.001449      0.356151     0.385006     0.000725     1.365883   \n2              0.000088      0.025049     0.026637     0.000283     0.146088   \n\n        LC_mean       LC_std        LC_min        LC_max  \n0  10892.717451   765.014962   9648.912511  12252.522087  \n1  32985.833422  2403.349800  29265.571768  37062.944908  \n2  25442.852221  1830.105197  22457.129272  28573.149193  \n\n[3 rows x 29 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>wavelength</th>\n      <th>p_signal_mean</th>\n      <th>p_signal_std</th>\n      <th>p_signal_min</th>\n      <th>p_signal_max</th>\n      <th>range_corr_signal_mean</th>\n      <th>range_corr_signal_std</th>\n      <th>range_corr_signal_min</th>\n      <th>range_corr_signal_max</th>\n      <th>range_corr_p_signal_mean</th>\n      <th>...</th>\n      <th>attbsc_molecular_min</th>\n      <th>attbsc_molecular_max</th>\n      <th>p_bg_bg_mean</th>\n      <th>p_bg_bg_std</th>\n      <th>p_bg_bg_min</th>\n      <th>p_bg_bg_max</th>\n      <th>LC_mean</th>\n      <th>LC_std</th>\n      <th>LC_min</th>\n      <th>LC_max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>355</td>\n      <td>88.280901</td>\n      <td>812.655000</td>\n      <td>0.003964</td>\n      <td>21699.117677</td>\n      <td>15.549797</td>\n      <td>24.042348</td>\n      <td>0.936831</td>\n      <td>134.568434</td>\n      <td>15.533479</td>\n      <td>...</td>\n      <td>0.000491</td>\n      <td>0.007664</td>\n      <td>0.136932</td>\n      <td>0.152953</td>\n      <td>0.000403</td>\n      <td>0.595537</td>\n      <td>10892.717451</td>\n      <td>765.014962</td>\n      <td>9648.912511</td>\n      <td>12252.522087</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>532</td>\n      <td>94.206550</td>\n      <td>844.996252</td>\n      <td>0.008764</td>\n      <td>23194.884773</td>\n      <td>22.552368</td>\n      <td>28.921022</td>\n      <td>2.071057</td>\n      <td>145.640789</td>\n      <td>22.529013</td>\n      <td>...</td>\n      <td>0.000210</td>\n      <td>0.001449</td>\n      <td>0.356151</td>\n      <td>0.385006</td>\n      <td>0.000725</td>\n      <td>1.365883</td>\n      <td>32985.833422</td>\n      <td>2403.349800</td>\n      <td>29265.571768</td>\n      <td>37062.944908</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1064</td>\n      <td>25.641477</td>\n      <td>223.603415</td>\n      <td>0.001039</td>\n      <td>6651.830518</td>\n      <td>7.308976</td>\n      <td>9.713228</td>\n      <td>0.245562</td>\n      <td>47.037022</td>\n      <td>7.304823</td>\n      <td>...</td>\n      <td>0.000015</td>\n      <td>0.000088</td>\n      <td>0.025049</td>\n      <td>0.026637</td>\n      <td>0.000283</td>\n      <td>0.146088</td>\n      <td>25442.852221</td>\n      <td>1830.105197</td>\n      <td>22457.129272</td>\n      <td>28573.149193</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows Ã— 29 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_fname = f\"stats_gen_{station.name}_{start_date.strftime('%Y-%m-%d')}_{end_date.strftime('%Y-%m-%d')}.csv\"\n",
    "csv_stats_path = os.path.join(data_folder, stats_fname)\n",
    "df_stats = pd.read_csv(csv_stats_path)\n",
    "df_stats"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "if CALC_STATS:\n",
    "    df_stats['range_corr_p_mean'] = mean\n",
    "    df_stats['range_corr_p_std'] = std\n",
    "    df_stats\n",
    "    df_stats.to_csv(csv_stats_path,index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Split files per time for each file in the database per sample time\n",
    "# TODO: move this to a new function prepare_generated_samples() after calling to create_generated_dataset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "CREATE_SAMPLES = False\n",
    "if CREATE_SAMPLES:\n",
    "    dataseting.prepare_generated_samples(station,start_date,end_date)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Update the current train and test datasets according to new paths in the generated dataset\n",
    "> such that the keys are not changed."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "gen_base_name = f\"dataset_gen_{station_name}_{start_date.strftime('%Y-%m-%d')}_{end_date.strftime('%Y-%m-%d')}\"\n",
    "csv_gen_path = os.path.join(data_folder,f\"{gen_base_name}.csv\")\n",
    "csv_gen_train_path = os.path.join(data_folder,f\"{gen_base_name}_train.csv\")\n",
    "csv_gen_test_path = os.path.join(data_folder,f\"{gen_base_name}_test.csv\")\n",
    "csv_gen_path, csv_gen_train_path,csv_gen_test_path\n",
    "\n",
    "df_gen = pd.read_csv(csv_gen_path)\n",
    "df_gen_train = pd.read_csv(csv_gen_train_path)\n",
    "df_gen_test = pd.read_csv(csv_gen_test_path)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# update p_bg with r2 multiplication\n",
    "> such that the keys are not changed.\n",
    "> TODO: If this improves the learning stage add it to the generation process and in dataseting proccess (including stats calculations)\n",
    "> TODO: it is better to use save_dataset2timesplits() in dataseting.py when doing time splis.\n",
    ">"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "CREATE_PBG_R2 =False\n",
    "df_gen['date'] = pd.to_datetime(df_gen['date'])\n",
    "grps_days = df_gen.groupby('date').groups\n",
    "mean = np.zeros(3)\n",
    "std = np.zeros(3)\n",
    "min = np.zeros(3)\n",
    "max = np.zeros(3)\n",
    "for day_dt, inds in grps_days.items():\n",
    "    wavelengths_grps =  df_gen.iloc[inds].groupby('wavelength').groups\n",
    "    tslices = dataseting.get_time_splits(station, day_dt, day_dt, '30min')\n",
    "    norm_scale = 1/(len(grps_days)*len(tslices))\n",
    "    r2_ds = calc_r2_ds(station,day_dt)\n",
    "    for ind,tslice in enumerate(tslices):\n",
    "        for ind_wav,wavelength in enumerate(wavelengths_grps):\n",
    "            ind_gen = wavelengths_grps[wavelength][ind]\n",
    "            path = df_gen.iloc[ind_gen]['bg_path']\n",
    "            path = path.replace('E:','D:')\n",
    "            bg_ds = prep.load_dataset(path)\n",
    "            if CREATE_PBG_R2:\n",
    "                hslice = slice (bg_ds.Height[0].values,bg_ds.Height[-1].values )\n",
    "                r2_ds_slice = r2_ds.sel(Height = hslice, Time =tslice, Wavelength = wavelength)\n",
    "                p_bg_r2 = xr.apply_ufunc(lambda p,r2 : p*r2,bg_ds.p_bg, r2_ds_slice, keep_attrs=True).\\\n",
    "                    assign_attrs({'long_name':r'$<p_{\\rm bg}>$'+ r'$\\cdot r^2$',\n",
    "                               'units':r'$\\rm photons \\cdot km^2$','info':'Daily averaged background signal - range corrected'})\n",
    "                bg_ds = bg_ds.assign(p_bg_r2=p_bg_r2)\n",
    "                prep.save_dataset(dataset=bg_ds, nc_path=path)\n",
    "\n",
    "            # update stats values:\n",
    "            mean[ind_wav]+= norm_scale * bg_ds.p_bg_r2.mean(dim={'Height', 'Time'}).values\n",
    "            std[ind_wav]+= norm_scale * bg_ds.p_bg_r2.std(dim={'Height', 'Time'}).values\n",
    "            min[ind_wav]+= norm_scale * bg_ds.p_bg_r2.min(dim={'Height', 'Time'}).values\n",
    "            max[ind_wav]+= norm_scale * bg_ds.p_bg_r2.max(dim={'Height', 'Time'}).values\n",
    "cols = ['p_bg_r2_bg_mean','p_bg_r2_bg_std','p_bg_r2_bg_min','p_bg_r2_bg_max']\n",
    "df_stats_p_pg = pd.DataFrame(data=[mean,std,min,max], index=cols).T\n",
    "new_df_stats = pd.concat([df_stats,df_stats_p_pg],axis=1)\n",
    "new_df_stats.to_csv(csv_stats_path,index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "lidar",
   "language": "python",
   "display_name": "lidar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}