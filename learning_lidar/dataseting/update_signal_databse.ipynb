{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import learning_lidar.utils.global_settings as gs\n",
    "import pandas as pd\n",
    "import learning_lidar.preprocessing.preprocessing as prep\n",
    "%matplotlib inline\n",
    "from learning_lidar.generation.daily_signals_generations_utils import  calc_poiss_measurement,calc_range_corr_measurement\n",
    "import learning_lidar.generation.generation_utils as gen_utils\n",
    "gs.set_visualization_settings()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Imports\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Set parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "'C:\\\\Users\\\\addalin\\\\Dropbox\\\\Lidar\\\\lidar_learning\\\\data'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_name = 'haifa'\n",
    "station = gs.Station(station_name)\n",
    "wavelengths = gs.LAMBDA_nm().get_elastic()\n",
    "\n",
    "main_folder = os.path.dirname(os.path.abspath(os.path.curdir))\n",
    "data_folder = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(os.path.curdir))), 'data')\n",
    "data_folder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Calculate poisson on \"clear\" signals, without background, for the given period.\n",
    "Adding range corrected with applies poisson noise to signal database\n",
    "# TODO: ADD this to generation.py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "start_date = datetime(2017, 9, 1)\n",
    "end_date = datetime(2017, 10, 31)\n",
    "dates = pd.date_range(start_date,end_date,freq='D')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "CALC_STATS=False\n",
    "if CALC_STATS:\n",
    "    base_folder = station.gen_signal_dataset\n",
    "    paths = [os.path.join(prep.get_month_folder_name(base_folder, dt),\n",
    "     gen_utils.get_gen_dataset_file_name(station, dt, data_source='signal')) for dt in dates]\n",
    "    mean = np.zeros(3)\n",
    "    std = np.zeros(3)\n",
    "    norm_scale = 1 / len(dates)\n",
    "\n",
    "    for cur_date,nc_path in zip(dates,paths):\n",
    "        signal_ds = prep.load_dataset(nc_path)\n",
    "        signal_ds\n",
    "        pn_ds = calc_poiss_measurement(station, cur_date, signal_ds.p)  # lidar measurement: pn ~Poiss(mu_p)\n",
    "        pr2n_ds = calc_range_corr_measurement(station, cur_date, pn_ds, signal_ds.r2) # range corrected measurement: pr2n = pn * r^2\n",
    "        pr2n_ds.attrs['info']+=' - w.o. background'\n",
    "        mean += pr2n_ds.mean(dim={'Height', 'Time'}).values\n",
    "        std += pr2n_ds.std(dim={'Height', 'Time'}).values\n",
    "        signal_ds = signal_ds.assign(range_corr_p =pr2n_ds)\n",
    "        gen_utils.save_generated_dataset(station, signal_ds,\n",
    "                                         data_source='signal',\n",
    "                                         save_mode='both',\n",
    "                                         profiles=['range_corr_p'])\n",
    "\n",
    "    mean *= norm_scale\n",
    "    std *= norm_scale"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Statistics for a period of the dataset\n",
    "> Loading the statistics database created in dataseting.py\n",
    "# TODO: ADD this to statistics calculation\n",
    "# TODO: ADD `range_corr_p` as  column to dataseting.py (gen_csv)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "stats_fname = f\"stats_gen_{station.name}_{start_date.strftime('%Y-%m-%d')}_{end_date.strftime('%Y-%m-%d')}.csv\"\n",
    "csv_stats_path = os.path.join(data_folder, stats_fname)\n",
    "df_stats = pd.read_csv(csv_stats_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "if CALC_STATS:\n",
    "    df_stats['range_corr_p_mean'] = mean\n",
    "    df_stats['range_corr_p_std'] = std\n",
    "    df_stats\n",
    "    df_stats.to_csv(csv_stats_path,index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Split files per time for each file in the database per sample time\n",
    "# TODO: move this to a new function prepare_generated_samples() after calling to create_generated_dataset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-12 07:34:40,353] {C:\\Users\\addalin\\Dropbox\\Lidar\\lidar_learning\\learning_lidar\\dataseting\\dataseting.py:553} INFO - Load and split datasets for 2017-09-01\n",
      "Split and save time slices for: range_corr_p, 355: 100%|██████████| 48/48 [00:06<00:00,  7.84it/s]\n",
      "Split and save time slices for: range_corr_p, 532: 100%|██████████| 48/48 [00:05<00:00,  8.14it/s]\n",
      "Split and save time slices for: range_corr_p, 1064: 100%|██████████| 48/48 [00:06<00:00,  7.48it/s]\n",
      "Split and save time slices for: range_corr, 355: 100%|██████████| 48/48 [00:06<00:00,  7.69it/s]\n",
      "Split and save time slices for: range_corr, 532: 100%|██████████| 48/48 [00:08<00:00,  5.86it/s]\n",
      "Split and save time slices for: range_corr, 1064: 100%|██████████| 48/48 [00:07<00:00,  6.06it/s]\n",
      "Split and save time slices for: range_corr, 355: 100%|██████████| 48/48 [00:05<00:00,  9.43it/s]\n",
      "Split and save time slices for: range_corr, 532: 100%|██████████| 48/48 [00:06<00:00,  7.09it/s]\n",
      "Split and save time slices for: range_corr, 1064: 100%|██████████| 48/48 [00:06<00:00,  7.31it/s]\n",
      "Split and save time slices for: p_bg, 355: 100%|██████████| 48/48 [00:06<00:00,  7.08it/s]\n",
      "Split and save time slices for: p_bg, 532: 100%|██████████| 48/48 [00:05<00:00,  9.39it/s]\n",
      "Split and save time slices for: p_bg, 1064: 100%|██████████| 48/48 [00:06<00:00,  7.11it/s]\n",
      "Split and save time slices for: attbsc, 355: 100%|██████████| 48/48 [00:06<00:00,  7.71it/s]\n",
      "Split and save time slices for: attbsc, 532: 100%|██████████| 48/48 [00:06<00:00,  7.93it/s]\n",
      "Split and save time slices for: attbsc, 1064: 100%|██████████| 48/48 [00:05<00:00,  8.25it/s]\n",
      "[2021-05-12 07:36:36,606] {C:\\Users\\addalin\\Dropbox\\Lidar\\lidar_learning\\learning_lidar\\dataseting\\dataseting.py:553} INFO - Load and split datasets for 2017-09-02\n",
      "Split and save time slices for: range_corr_p, 355: 100%|██████████| 48/48 [00:05<00:00,  8.06it/s]\n",
      "Split and save time slices for: range_corr_p, 532: 100%|██████████| 48/48 [00:06<00:00,  7.32it/s]\n",
      "Split and save time slices for: range_corr_p, 1064: 100%|██████████| 48/48 [00:07<00:00,  6.74it/s]\n",
      "Split and save time slices for: range_corr, 355: 100%|██████████| 48/48 [00:06<00:00,  7.72it/s]\n",
      "Split and save time slices for: range_corr, 532: 100%|██████████| 48/48 [00:06<00:00,  7.83it/s]\n",
      "Split and save time slices for: range_corr, 1064: 100%|██████████| 48/48 [00:06<00:00,  7.42it/s]\n",
      "Split and save time slices for: range_corr, 355: 100%|██████████| 48/48 [00:05<00:00,  8.53it/s]\n",
      "Split and save time slices for: range_corr, 532: 100%|██████████| 48/48 [00:07<00:00,  6.70it/s]\n",
      "Split and save time slices for: range_corr, 1064: 100%|██████████| 48/48 [00:05<00:00,  9.07it/s]\n",
      "Split and save time slices for: p_bg, 355: 100%|██████████| 48/48 [00:06<00:00,  7.17it/s]\n",
      "Split and save time slices for: p_bg, 532:  96%|█████████▌| 46/48 [00:05<00:00, 10.26it/s]"
     ]
    }
   ],
   "source": [
    "import learning_lidar.dataseting.dataseting as dataseting\n",
    "start_date = datetime(2017, 9, 1)\n",
    "end_date = datetime(2017, 10, 31)\n",
    "dataseting.prepare_generated_samples(station,start_date,end_date)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Update the current train and test datasets according to new paths in the generated dataset\n",
    "> such that the keys are not changed."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "gen_base_name = f\"dataset_gen_{station_name}_{start_date.strftime('%Y-%m-%d')}_{end_date.strftime('%Y-%m-%d')}\"\n",
    "csv_gen_path = os.path.join(data_folder,f\"{gen_base_name}.csv\")\n",
    "csv_gen_train_path = os.path.join(data_folder,f\"{gen_base_name}_train.csv\")\n",
    "csv_gen_test_path = os.path.join(data_folder,f\"{gen_base_name}_test.csv\")\n",
    "csv_gen_path, csv_gen_train_path,csv_gen_test_path\n",
    "\n",
    "df_gen = pd.read_csv(csv_gen_path)\n",
    "df_gen_train = pd.read_csv(csv_gen_train_path)\n",
    "df_gen_test = pd.read_csv(csv_gen_test_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "def update_row_df(row,orig_df):\n",
    "    idx = row['idx']\n",
    "    row_orig = orig_df.iloc[idx]\n",
    "    row['lidar_path'] = row_orig['lidar_path']\n",
    "    row['signal_path'] = row_orig['signal_path']\n",
    "    row['signal_p_path'] = row_orig['signal_p_path']\n",
    "    row['molecular_path'] = row_orig['molecular_path']\n",
    "    return  row\n",
    "\n",
    "new_train_df = df_gen_train.apply(update_row_df,\n",
    "                                  args=(df_gen,),\n",
    "                                  axis=1,\n",
    "                                  result_type='expand')\n",
    "new_train_df\n",
    "\n",
    "new_test_df = df_gen_test.apply(update_row_df,\n",
    "                                  args=(df_gen,),\n",
    "                                  axis=1,\n",
    "                                  result_type='expand')\n",
    "new_test_df\n",
    "\n",
    "csv_genN_train_path = os.path.join(data_folder,f\"{gen_base_name}_train_new.csv\")\n",
    "csv_genN_test_path = os.path.join(data_folder,f\"{gen_base_name}_test_new.csv\")\n",
    "new_train_df.to_csv(csv_genN_train_path,index=False)\n",
    "new_test_df.to_csv(csv_genN_test_path,index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "lidar",
   "language": "python",
   "display_name": "lidar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}