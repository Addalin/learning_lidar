{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import tune\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import  seaborn as sns\n",
    "import learning_lidar.utils.vis_utils as vis_utils\n",
    "import matplotlib as mpl\n",
    "sns.set_palette(sns.color_palette(\"tab10\"))\n",
    "\n",
    "plt.rcParams['figure.dpi'] = vis_utils.FIGURE_DPI\n",
    "plt.rcParams['savefig.dpi'] = vis_utils.SAVEFIG_DPI\n",
    "\n",
    "sns.set_theme()\n",
    "sns.set_context(\"paper\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "plt.rc('font', **{'family': 'sans-serif', 'sans-serif': ['Helvetica']})\n",
    "plt.rc('text', usetex=False)\n",
    "#plt.rc('font', family='serif')\n",
    "#plt.rcParams['text.latex.preamble'] = r\"\\usepackage{amsmath}\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "def extract_powers(row, in_channels):\n",
    "    powers = eval(row['powers']) if type(row['powers'])==str else None\n",
    "    pow_y = np.array(powers[1])[0] if type(powers)==tuple else None\n",
    "    pow_x = np.array(powers[0]) if type(powers)==tuple else None\n",
    "    pow_xi = np.zeros(in_channels)\n",
    "    if type(pow_x)==np.ndarray:\n",
    "        for chan in range(in_channels):\n",
    "            pow_xi[chan] = pow_x[chan] if  (len(pow_x)>=chan+1) else None\n",
    "    else:\n",
    "        for chan in range(in_channels):\n",
    "            pow_xi[chan] = None\n",
    "    return [pow_y,*pow_xi]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "base_folder = os.path.dirname(os.path.dirname(os.path.abspath(os.curdir)))\n",
    "results_folder = os.path.join(base_folder, 'results')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% paths\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# postprocessing LCNET results from jason state files saved in  `runs_board.xlsx`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-109-1884f03031e8>:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  runs_df = runs_df[runs_df.include==True][runs_df.state!='PENDING']\n"
     ]
    }
   ],
   "source": [
    "runs_df = pd.read_excel(os.path.join(results_folder,'runs_board.xlsx'))\n",
    "runs_df = runs_df[runs_df.include==True][runs_df.state!='PENDING']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\addalin\\Dropbox\\Lidar\\lidar_learning\\results\\main_2021-05-20_07-01-41\\experiment_results.csv 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\addalin\\Dropbox\\Lidar\\lidar_learning\\results\\main_2021-05-20_13-05-53\\experiment_results.csv 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\addalin\\Dropbox\\Lidar\\lidar_learning\\results\\main_2021-05-21_01-40-10\\experiment_results.csv 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\addalin\\Dropbox\\Lidar\\lidar_learning\\results\\main_2021-05-21_12-12-43\\experiment_results.csv 17\n",
      "C:\\Users\\addalin\\Dropbox\\Lidar\\lidar_learning\\results\\main_2021-05-22_20-09-17\\experiment_results.csv"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "Couldn't read config from 17 paths\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\addalin\\Dropbox\\Lidar\\lidar_learning\\results\\main_2021-05-22_23-36-51\\experiment_results.csv 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\addalin\\Dropbox\\Lidar\\lidar_learning\\results\\main_2021-05-23_19-35-00\\experiment_results.csv 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\addalin\\Dropbox\\Lidar\\lidar_learning\\results\\main_2021-05-23_23-40-05\\experiment_results.csv 21\n",
      "C:\\Users\\addalin\\Dropbox\\Lidar\\lidar_learning\\results\\main_2021-05-24_08-38-28\\experiment_results.csv"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 22\n",
      "C:\\Users\\addalin\\Dropbox\\Lidar\\lidar_learning\\results\\main_2021-05-24_11-20-46\\experiment_results.csv"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 23\n",
      "C:\\Users\\addalin\\Dropbox\\Lidar\\lidar_learning\\results\\main_2021-05-24_16-19-23\\experiment_results.csv"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 24\n",
      "C:\\Users\\addalin\\Dropbox\\Lidar\\lidar_learning\\results\\main_2021-05-24_20-51-26\\experiment_results.csv"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 25\n",
      "C:\\Users\\addalin\\Dropbox\\Lidar\\lidar_learning\\results\\main_2021-05-25_14-38-18\\experiment_results.csv"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 27\n",
      "C:\\Users\\addalin\\Dropbox\\Lidar\\lidar_learning\\results\\main_2021-05-25_17-50-10\\experiment_results.csv 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\addalin\\Dropbox\\Lidar\\lidar_learning\\results\\main_2021-05-26_11-06-37\\experiment_results.csv 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\addalin\\Dropbox\\Lidar\\lidar_learning\\results\\main_2021-05-27_00-39-22\\experiment_results.csv 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\addalin\\Dropbox\\Lidar\\lidar_learning\\results\\main_2021-05-27_11-33-28\\experiment_results.csv 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\addalin\\Dropbox\\Lidar\\lidar_learning\\results\\main_2021-05-27_17-47-57\\experiment_results.csv 32\n",
      "C:\\Users\\addalin\\Dropbox\\Lidar\\lidar_learning\\results\\main_2021-05-27_22-18-22\\experiment_results.csv 33\n",
      "C:\\Users\\addalin\\Dropbox\\Lidar\\lidar_learning\\results\\main_2021-05-28_20-06-11\\experiment_results.csv 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\addalin\\Dropbox\\Lidar\\lidar_learning\\results\\main_2021-05-30_23-15-43\\experiment_results.csv 35\n",
      "C:\\Users\\addalin\\Dropbox\\Lidar\\lidar_learning\\results\\main_2021-06-06_22-33-17\\experiment_results.csv 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\addalin\\Dropbox\\Lidar\\lidar_learning\\results\\main_2021-06-07_11-14-36\\experiment_results.csv 37\n",
      "C:\\Users\\addalin\\Dropbox\\Lidar\\lidar_learning\\results\\main_2021-06-07_16-30-09\\experiment_results.csv 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\addalin\\Dropbox\\Lidar\\lidar_learning\\results\\main_2021-06-07_22-18-28\\experiment_results.csv 39\n",
      "C:\\Users\\addalin\\Dropbox\\Lidar\\lidar_learning\\results\\main_2021-06-08_21-35-18\\experiment_results.csv 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\addalin\\Dropbox\\Lidar\\lidar_learning\\results\\main_2021-06-10_00-07-49\\experiment_results.csv 41\n",
      "C:\\Users\\addalin\\Dropbox\\Lidar\\lidar_learning\\results\\main_2021-06-10_14-06-50\\experiment_results.csv 42\n",
      "C:\\Users\\addalin\\Dropbox\\Lidar\\lidar_learning\\results\\main_2021-06-10_16-57-29\\experiment_results.csv 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\addalin\\Dropbox\\Lidar\\lidar_learning\\results\\main_2021-06-12_18-44-17\\experiment_results.csv 67\n",
      "C:\\Users\\addalin\\Dropbox\\Lidar\\lidar_learning\\results\\main_2021-06-13_18-06-08\\experiment_results.csv 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\addalin\\Dropbox\\Lidar\\lidar_learning\\results\\main_2021-06-15_12-11-13\\experiment_results.csv 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\addalin\\Dropbox\\Lidar\\lidar_learning\\results\\main_2021-06-16_14-29-45\\experiment_results.csv 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "Couldn't read config from 143 paths\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\addalin\\Dropbox\\Lidar\\lidar_learning\\results\\main_2021-06-17_09-53-05\\experiment_results.csv 71\n",
      "C:\\Users\\addalin\\Dropbox\\Lidar\\lidar_learning\\results\\main_2021-07-19_13-35-35\\experiment_results.csv 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\addalin\\Dropbox\\Lidar\\lidar_learning\\results\\main_2021-07-19_21-26-42\\experiment_results.csv 77\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid file path or buffer object type: <class 'float'>",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-110-a98902d88c69>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     85\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     86\u001B[0m \u001B[0mpaths\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mrow\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'results_csv'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0midx\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mrow\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mruns_df\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0miterrows\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 87\u001B[1;33m \u001B[0mresults_dfs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mpath\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mpaths\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     88\u001B[0m \u001B[0mtotal_results\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconcat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresults_dfs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mignore_index\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     89\u001B[0m \u001B[1;31m# %%\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-110-a98902d88c69>\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     85\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     86\u001B[0m \u001B[0mpaths\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mrow\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'results_csv'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0midx\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mrow\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mruns_df\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0miterrows\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 87\u001B[1;33m \u001B[0mresults_dfs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mpath\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mpaths\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     88\u001B[0m \u001B[0mtotal_results\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconcat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresults_dfs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mignore_index\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     89\u001B[0m \u001B[1;31m# %%\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\lidar\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001B[0m\n\u001B[0;32m    686\u001B[0m     )\n\u001B[0;32m    687\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 688\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    689\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    690\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\lidar\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    434\u001B[0m     \u001B[1;31m# though mypy handling of conditional imports is difficult.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    435\u001B[0m     \u001B[1;31m# See https://github.com/python/mypy/issues/1297\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 436\u001B[1;33m     fp_or_buf, _, compression, should_close = get_filepath_or_buffer(\n\u001B[0m\u001B[0;32m    437\u001B[0m         \u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mencoding\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcompression\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    438\u001B[0m     )\n",
      "\u001B[1;32m~\\.conda\\envs\\lidar\\lib\\site-packages\\pandas\\io\\common.py\u001B[0m in \u001B[0;36mget_filepath_or_buffer\u001B[1;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001B[0m\n\u001B[0;32m    241\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mis_file_like\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    242\u001B[0m         \u001B[0mmsg\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34mf\"Invalid file path or buffer object type: {type(filepath_or_buffer)}\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 243\u001B[1;33m         \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmsg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    244\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    245\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcompression\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Invalid file path or buffer object type: <class 'float'>"
     ]
    }
   ],
   "source": [
    "for idx,row in runs_df.iterrows():\n",
    "    #row = runs_df.iloc[idx]\n",
    "    try:\n",
    "        state_fname = sorted(glob.glob(os.path.join( row.experiment_folder,r'experiment_state*.json')))[-1]\n",
    "        analysis = tune.ExperimentAnalysis(state_fname)\n",
    "        ignore_MARELoss = \"MARELoss\" in [row.field_to_ignore]\n",
    "        analysis.default_metric = \"MARELoss\" if ignore_MARELoss else \"MARELoss\"\n",
    "        analysis.default_mode=\"min\"\n",
    "        results_df = analysis.dataframe(metric=\"MARELoss\", mode=\"min\",)\n",
    "\n",
    "        # update fields:\n",
    "        if ignore_MARELoss:\n",
    "            results_df[\"MARELoss\"]=None\n",
    "\n",
    "        # rename column names:\n",
    "        cols = results_df.columns.values.tolist()\n",
    "        new_cols = [col.replace('config/',\"\") for col in cols]\n",
    "        dict_cols ={}\n",
    "        for col,new_col in zip(cols, new_cols):\n",
    "            dict_cols.update({col:new_col})\n",
    "        results_df = results_df.rename(columns= dict_cols)\n",
    "\n",
    "        # update power values:\n",
    "        # TODO: incase Adi Vainiger: use_bg : TRUE, range_corr and pow_x3 is not given --> use the default values to 0.5\n",
    "        len_pow = len(results_df[results_df.use_power==True])\n",
    "        len_no_pow = len(results_df[results_df.use_power==False])\n",
    "        len_pows = len(results_df[results_df.use_power !=False])\n",
    "        if len_no_pow>0:\n",
    "            results_df.loc[results_df[results_df.use_power==False].index,'powers']= ''\n",
    "        if len_pows!=len_pow:\n",
    "            results_df.loc[results_df[results_df.use_power!=False].index,'powers']=results_df.use_power\n",
    "            results_df.loc[results_df[results_df.use_power!=False].index,'use_power']=True\n",
    "        else:\n",
    "            results_df.loc[results_df[results_df.use_power==True].index,'powers']= '([0.5,0.5],[0.5])'\n",
    "\n",
    "        # Update Notes\n",
    "        note = row['note']\n",
    "        results_df['note']= note if type(note)==str else 'ok'\n",
    "\n",
    "        # drop irrelevant columns:\n",
    "        drop_cols = [ 'time_this_iter_s', 'should_checkpoint', 'done',\n",
    "                   'timesteps_total', 'episodes_total',\n",
    "                   'experiment_id',  'timestamp',  'pid', 'hostname',\n",
    "                   'node_ip', 'time_since_restore', 'timesteps_since_restore',\n",
    "                   'iterations_since_restore']\n",
    "        results_df.drop(columns=drop_cols,inplace=True)\n",
    "\n",
    "\n",
    "        # reorganize columns:\n",
    "        new_order = ['trial_id', 'date','time_total_s','training_iteration',\n",
    "                     'loss', 'MARELoss',\n",
    "                     'bsize', 'dfilter', 'dnorm','fc_size', 'hsizes', 'lr',\n",
    "                     'ltype', 'source', 'use_bg', 'use_power','powers','note','logdir']\n",
    "        results_df = results_df.reindex(columns=new_order)\n",
    "\n",
    "        # keep index trial (especially for cases when trails are ignored)\n",
    "        #results_df['idx']=results_df.index\n",
    "        #new_cols = ['idx']\n",
    "        #new_cols.extend(cols)\n",
    "        #results_df = results_df.reindex(columns=new_cols)\n",
    "\n",
    "        # remove irrelevant trials (e.g. when dnorm had wrong calculation)\n",
    "        if row.trial_to_ignore is not np.nan:\n",
    "            key,cond = eval(row.trial_to_ignore)\n",
    "            results_df.drop(index=results_df[results_df[key]==cond].index,inplace=True)\n",
    "\n",
    "        # save csv\n",
    "        results_csv = os.path.join(analysis._experiment_dir, f'experiment_results.csv')\n",
    "        results_df.to_csv(results_csv, index=False)\n",
    "\n",
    "        # update csv path in main runs_board\n",
    "        runs_df.loc[idx,'results_csv']=results_csv\n",
    "        print(results_csv,idx)\n",
    "\n",
    "    except:\n",
    "        continue\n",
    "# TODO: save runs_df with results_csv paths\n",
    "\n",
    "# %%\n",
    "\n",
    "#runs_df\n",
    "\n",
    "\n",
    "# %% concatante all csv files with include =1\n",
    "\n",
    "paths = [row['results_csv'] for idx,row in runs_df.iterrows()]\n",
    "results_dfs=[pd.read_csv(path) for path in paths]\n",
    "total_results = pd.concat(results_dfs,ignore_index=True)\n",
    "# %%\n",
    "total_results['fc_size'] = total_results.fc_size.apply(lambda x: eval(str(x))[0])\n",
    "# update powers\n",
    "in_channels = 3\n",
    "res= total_results.apply(extract_powers,args=(in_channels,), axis=1, result_type='expand')\n",
    "cols_powx = [f\"pow_x{ind+1}\" for ind in range(in_channels)]\n",
    "res.rename( columns={0:'pow_y',1:cols_powx[0],2:cols_powx[1],3:cols_powx[2]},inplace=True)\n",
    "total_results[res.columns.values] = res\n",
    "total_results['powers'] = total_results.powers.apply(lambda x: eval(x) if type(x)==str else None)\n",
    "\n",
    "# %%\n",
    "\n",
    "hsizes=total_results.hsizes.apply(lambda x: eval(x))\n",
    "total_results['u_hsize']=hsizes.apply(lambda x: all([(hi==x[0]) for hi in x])) # The test of changing the with at the last level , didn't show improvements"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wavelengths=[]\n",
    "filtered = total_results.dfilter.apply(lambda x:type(x)==str)\n",
    "inds = total_results.dfilter[filtered].index\n",
    "for ind,f in enumerate(filtered):\n",
    "    if f:\n",
    "        [filter_by,filter_values] = eval(total_results.dfilter.iloc[ind])\n",
    "        if filter_by=='wavelength':\n",
    "            wavelength = tuple(filter_values) if len(filter_values)>1 else filter_values[0]\n",
    "        else:\n",
    "            wavelength = 'all'\n",
    "    else:\n",
    "        wavelength='all'\n",
    "    wavelengths.append(wavelength)\n",
    "\n",
    "total_results['wavelength'] = wavelengths\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "analyse_results = total_results[total_results.training_iteration>=1]\n",
    "#analyse_results = analyse_results[analyse_results.note=='ok']\n",
    "analyse_results = analyse_results[analyse_results.u_hsize]\n",
    "\n",
    "# %%\n",
    "configs= []\n",
    "use_bg = []\n",
    "for idx,row in analyse_results.iterrows():\n",
    "    hsize = eval(row.hsizes)[0]\n",
    "    fcsize = row.fc_size\n",
    "    if (hsize==4) and (fcsize==16):\n",
    "        configs.append('A')\n",
    "    elif (hsize==4) and (fcsize==32):\n",
    "        configs.append('B')\n",
    "    elif (hsize==5) and (fcsize==16):\n",
    "        configs.append('C')\n",
    "    elif (hsize==5) and (fcsize==32):\n",
    "        configs.append('D')\n",
    "    elif (hsize==6) and (fcsize==16):\n",
    "        configs.append('E')\n",
    "    elif (hsize==6) and (fcsize==32):\n",
    "        configs.append('F')\n",
    "    else:\n",
    "        configs.append('Other')\n",
    "\n",
    "    flag_bg = row.use_bg\n",
    "    if type(flag_bg)==str:\n",
    "        if flag_bg=='False' or flag_bg=='True':\n",
    "            use_bg.append(eval(flag_bg))\n",
    "        else :\n",
    "            use_bg.append(flag_bg)\n",
    "    else:\n",
    "        use_bg.append(flag_bg)\n",
    "\n",
    "analyse_results['config'] = configs\n",
    "analyse_results['use_bg'] = use_bg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Choosing Learning rate\n",
    "1. X: range_corr(lidar), attbsc(molecular). Y:LC\n",
    "> use_normalization = False\n",
    "> use_power = True\n",
    "> source = lidar"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lidar_res = analyse_results[analyse_results.source=='lidar' ]\n",
    "lidar_res = lidar_res[lidar_res.use_bg==False]\n",
    "pow_lidar = lidar_res[(~lidar_res.dnorm & lidar_res.use_power ) ]\n",
    "pow_lidar[pow_lidar.note=='initial_db_overlap']\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(7, 5))\n",
    "pd.pivot_table(pow_lidar[pow_lidar.bsize==32][pow_lidar.fc_size>4],#[pow_lidar.note=='ok'],\n",
    "               values=['MARELoss'],\n",
    "               columns= ['lr'],\n",
    "               index=['source'],#'fc_size'],\n",
    "               aggfunc=np.min).\\\n",
    "    plot(kind='bar',ax =ax, title='Choosing learning Rate')\n",
    "ax.get_yaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "ax.grid(b=True, which='minor', color='w', linewidth=0.8)\n",
    "ax.grid(b=True, which='major', color='w', linewidth=1.2)\n",
    "ax.xaxis.grid(False)\n",
    "ax.set_ylabel(r'Relative error $[\\%]$')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. FC vs. hidden sizes\n",
    "1. X: range_corr(lidar), attbsc(molecular). Y:LC\n",
    "> use_normalization = False\n",
    "> use_power = True\n",
    "> source = lidar\n",
    "> lr = 0.001 or lr = 0.005"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_wav = analyse_results #[analyse_results.wavelength=='all']\n",
    "all_wavs_configABCD = all_wav[all_wav.config!='Other']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(7, 5))\n",
    "\n",
    "pd.pivot_table(all_wavs_configABCD[all_wavs_configABCD.use_bg!=True][all_wavs_configABCD.use_bg!='range_corr'][all_wavs_configABCD.use_power!=False][all_wavs_configABCD.note=='initial_db'][all_wavs_configABCD.wavelength=='all'],\n",
    "               values=['MARELoss'],\n",
    "               columns= ['config'],\n",
    "               index=['pow_x1','pow_x2'],\n",
    "               aggfunc=np.mean).\\\n",
    "    plot(kind='bar',ax =ax, title='Average loss on initial database \\n Searching for an optimal power transform ')\n",
    "ax.get_yaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "ax.grid(b=True, which='minor', color='w', linewidth=0.8)\n",
    "ax.grid(b=True, which='major', color='w', linewidth=1.2)\n",
    "ax.set_ylabel(r'Relative error $[\\%]$')\n",
    "ax.xaxis.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(7, 5))\n",
    "\n",
    "pd.pivot_table(all_wavs_configABCD[all_wavs_configABCD.use_bg!=True][all_wavs_configABCD.use_bg!='range_corr'][all_wavs_configABCD.note=='initial_db'][all_wavs_configABCD.wavelength=='all'],\n",
    "               values=['MARELoss'],\n",
    "               columns= ['config'],\n",
    "               index=['use_power'],\n",
    "               aggfunc=np.min).\\\n",
    "    plot(kind='bar',ax =ax, title='Minimal loss on initial database \\n Testing the contribution of power transform ')\n",
    "ax.get_yaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "ax.grid(b=True, which='minor', color='w', linewidth=0.8)\n",
    "ax.grid(b=True, which='major', color='w', linewidth=1.2)\n",
    "ax.set_ylabel(r'Relative error $[\\%]$')\n",
    "ax.xaxis.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(7, 5))\n",
    "\n",
    "pd.pivot_table(all_wavs_configABCD[all_wavs_configABCD.use_bg==False][all_wavs_configABCD.note=='initial_db'],\n",
    "               values=['MARELoss'],\n",
    "               columns= ['config'],\n",
    "               index=['wavelength'],\n",
    "               aggfunc=np.mean).\\\n",
    "    plot(kind='bar',ax =ax, title='Average loss on initial database \\n Wavelengths separation comparison ')\n",
    "ax.get_yaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "ax.grid(b=True, which='minor', color='w', linewidth=0.8)\n",
    "ax.grid(b=True, which='major', color='w', linewidth=1.2)\n",
    "ax.set_ylabel(r'Relative error $[\\%]$')\n",
    "ax.xaxis.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(11, 7))\n",
    "\n",
    "pd.pivot_table(all_wavs_configABCD[all_wavs_configABCD.use_bg==False]\n",
    "               [all_wavs_configABCD.note=='initial_db'][all_wavs_configABCD.wavelength!='all'],\n",
    "               values=['MARELoss'],\n",
    "               columns= ['config'],\n",
    "               index=['wavelength','pow_x1','pow_x2'],\n",
    "               aggfunc=np.min).\\\n",
    "    plot(kind='bar',ax =ax, title='Average loss on initial database \\n Searching for an optimal power transform ')\n",
    "ax.get_yaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "ax.grid(b=True, which='minor', color='w', linewidth=0.8)\n",
    "ax.grid(b=True, which='major', color='w', linewidth=1.2)\n",
    "ax.set_ylabel(r'Relative error $[\\%]$')\n",
    "ax.xaxis.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(11, 7))\n",
    "\n",
    "pd.pivot_table(all_wavs_configABCD[all_wavs_configABCD.note=='initial_db'][all_wavs_configABCD.wavelength=='all'],\n",
    "               values=['MARELoss'],\n",
    "               columns= ['config'],\n",
    "               index=['use_bg'],\n",
    "               aggfunc=np.min).\\\n",
    "    plot(kind='bar',ax =ax, title='Minimal loss on initial database \\n Testing the background contribution.')\n",
    "ax.get_yaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "ax.grid(b=True, which='minor', color='w', linewidth=0.8)\n",
    "ax.grid(b=True, which='major', color='w', linewidth=1.2)\n",
    "ax.set_ylabel(r'Relative error $[\\%]$')\n",
    "ax.set_ylim([0.0, 0.175])\n",
    "ax.xaxis.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(11, 7))\n",
    "\n",
    "pd.pivot_table(all_wavs_configABCD[all_wavs_configABCD.note=='initial_db'][all_wavs_configABCD.wavelength!='all'],\n",
    "               values=['MARELoss'],\n",
    "               columns= ['config'],\n",
    "               index=['use_bg'],\n",
    "               aggfunc=np.min).\\\n",
    "    plot(kind='bar',ax =ax, title='Minimal loss on initial database \\n Testing the background contribution, for wavelength separation')\n",
    "ax.get_yaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "ax.grid(b=True, which='minor', color='w', linewidth=0.8)\n",
    "ax.grid(b=True, which='major', color='w', linewidth=1.2)\n",
    "ax.set_ylim([0.0, 0.175])\n",
    "ax.set_ylabel(r'Relative error $[\\%]$')\n",
    "ax.xaxis.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(13, 7))\n",
    "\n",
    "pd.pivot_table(all_wavs_configABCD[all_wavs_configABCD.note=='initial_db'][all_wavs_configABCD.wavelength!='all'],\n",
    "               values=['MARELoss'],\n",
    "               columns= ['config'],\n",
    "               index=['wavelength','use_bg'],\n",
    "               aggfunc=np.mean).\\\n",
    "    plot(kind='bar',ax =ax, title='Minimal loss on initial database \\n Testing the background contribution - separated wavelengths')\n",
    "ax.get_yaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "ax.grid(b=True, which='minor', color='w', linewidth=0.8)\n",
    "ax.grid(b=True, which='major', color='w', linewidth=1.2)\n",
    "ax.set_ylabel(r'Relative error $[\\%]$')\n",
    "ax.xaxis.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#wavelength =532\n",
    "for wavelength in [355,532,1064]:\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(11, 7))\n",
    "\n",
    "    pd.pivot_table(all_wavs_configABCD[all_wavs_configABCD.note=='initial_db']\n",
    "                   [all_wavs_configABCD.wavelength==wavelength],\n",
    "                   values=['MARELoss'],\n",
    "                   columns= ['config'],\n",
    "                   index=['use_bg', 'pow_x2','pow_x3'],\n",
    "                   aggfunc=np.min).\\\n",
    "        plot(kind='bar',ax =ax, title=f'Minimal loss on initial database \\n'+fr'Testing the background contribution - ${wavelength}[\\rm nm]$')\n",
    "    ax.get_yaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "    ax.grid(b=True, which='minor', color='w', linewidth=0.8)\n",
    "    ax.grid(b=True, which='major', color='w', linewidth=1.2)\n",
    "    ax.set_ylabel(r'Relative error $[\\%]$')\n",
    "    ax.xaxis.grid(False)\n",
    "    ax.set_ylim([0.0, 0.2])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(7, 5))\n",
    "\n",
    "pd.pivot_table(all_wavs_configABCD[all_wavs_configABCD.use_bg!=True][all_wavs_configABCD.use_bg!='range_corr']\n",
    "               [all_wavs_configABCD.note=='extended_db'][all_wavs_configABCD.wavelength=='all'],\n",
    "               values=['MARELoss'],\n",
    "               columns= ['config'],\n",
    "               index=['use_power'],\n",
    "               aggfunc=np.min).\\\n",
    "    plot(kind='bar',ax =ax, title='Minimal loss on initial database \\n Testing the contribution of power transform ')\n",
    "ax.get_yaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "ax.grid(b=True, which='minor', color='w', linewidth=0.8)\n",
    "ax.grid(b=True, which='major', color='w', linewidth=1.2)\n",
    "ax.set_ylabel(r'Relative error $[\\%]$')\n",
    "ax.xaxis.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(7, 5))\n",
    "\n",
    "pd.pivot_table(all_wavs_configABCD[all_wavs_configABCD.use_bg==False]\n",
    "               [all_wavs_configABCD.note=='extended_db'],\n",
    "               values=['MARELoss'],\n",
    "               columns= ['config'],\n",
    "               index=['wavelength'],\n",
    "               aggfunc=np.min).\\\n",
    "    plot(kind='bar',ax =ax, title='Average loss on the extended database \\n Wavelengths separation comparison ')\n",
    "ax.get_yaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "ax.grid(b=True, which='minor', color='w', linewidth=0.8)\n",
    "ax.grid(b=True, which='major', color='w', linewidth=1.2)\n",
    "ax.set_ylabel(r'Relative error $[\\%]$')\n",
    "ax.xaxis.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(7, 5))\n",
    "\n",
    "pd.pivot_table(all_wavs_configABCD[all_wavs_configABCD.use_bg==False][all_wavs_configABCD.note=='extended_db'],\n",
    "               values=['MARELoss'],\n",
    "               columns= ['config'],\n",
    "               index=['wavelength','use_power'],\n",
    "               aggfunc=np.min).\\\n",
    "    plot(kind='bar',ax =ax, title='Minimal loss on the extended database \\n Testing wavelengths separation')\n",
    "ax.get_yaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "ax.grid(b=True, which='minor', color='w', linewidth=0.8)\n",
    "ax.grid(b=True, which='major', color='w', linewidth=1.2)\n",
    "ax.set_ylabel(r'Relative error $[\\%]$')\n",
    "ax.xaxis.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(11, 7))\n",
    "\n",
    "pd.pivot_table(all_wavs_configABCD[all_wavs_configABCD.use_bg==False]\n",
    "               [all_wavs_configABCD.note=='extended_db'][all_wavs_configABCD.wavelength!='all'],\n",
    "               values=['MARELoss'],\n",
    "               columns= ['config'],\n",
    "               index=['wavelength','pow_x1','pow_x2'],\n",
    "               aggfunc=np.min).\\\n",
    "    plot(kind='bar',ax =ax, title='Minimal loss on extended database \\n Searching for an optimal power transform ')\n",
    "ax.get_yaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "ax.grid(b=True, which='minor', color='w', linewidth=0.8)\n",
    "ax.grid(b=True, which='major', color='w', linewidth=1.2)\n",
    "ax.set_ylabel(r'Relative error $[\\%]$')\n",
    "ax.xaxis.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_wavs_configABCD[all_wavs_configABCD.wavelength==532][all_wavs_configABCD.use_bg==False].note"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for wavelength in [355,532,1064]:\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(11, 9))\n",
    "    pd.pivot_table(all_wavs_configABCD[all_wavs_configABCD.use_bg==False][all_wavs_configABCD.wavelength==wavelength],\n",
    "                   values=['MARELoss'],\n",
    "                   columns= ['config'],\n",
    "                   index=['pow_x1','pow_x2','note'],\n",
    "                   aggfunc=np.mean).\\\n",
    "        plot(kind='bar',ax =ax, title=f'Minimal loss on extended database \\n Testing 1st model - '+ fr'${wavelength}[\\rm nm]$' )\n",
    "    ax.get_yaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "    ax.grid(b=True, which='minor', color='w', linewidth=0.8)\n",
    "    ax.grid(b=True, which='major', color='w', linewidth=1.2)\n",
    "    ax.set_ylabel(r'Relative error $[\\%]$')\n",
    "    ax.xaxis.grid(False)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(11, 7))\n",
    "\n",
    "pd.pivot_table(all_wavs_configABCD[all_wavs_configABCD.note=='extended_db']\n",
    "               [all_wavs_configABCD.wavelength!='all'],\n",
    "               values=['MARELoss'],\n",
    "               columns= ['config'],\n",
    "               index=['use_bg'],\n",
    "               aggfunc=np.min).\\\n",
    "    plot(kind='bar',ax =ax, title='Minimal loss on extended database \\n Testing the background contribution - separated wavelengths')\n",
    "ax.get_yaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "ax.grid(b=True, which='minor', color='w', linewidth=0.8)\n",
    "ax.grid(b=True, which='major', color='w', linewidth=1.2)\n",
    "ax.set_ylabel(r'Relative error $[\\%]$')\n",
    "ax.xaxis.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for wavelength in [355,532,1064]:\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(11, 9))\n",
    "    pd.pivot_table(all_wavs_configABCD[all_wavs_configABCD.use_power][all_wavs_configABCD.wavelength==wavelength],#[all_wavs_configABCD.note!='initial_db_overlap'],\n",
    "                   values=['MARELoss'],\n",
    "                   columns= ['config'],\n",
    "                   index=['use_bg', 'note'],\n",
    "                   aggfunc=np.min).\\\n",
    "        plot(kind='bar',ax =ax, title=f'Minimal loss on extended database \\n Testing 2nd model - '+ fr'${wavelength}[\\rm nm]$' )\n",
    "    ax.get_yaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "    ax.grid(b=True, which='minor', color='w', linewidth=0.8)\n",
    "    ax.grid(b=True, which='major', color='w', linewidth=1.2)\n",
    "    ax.set_ylabel(r'Relative error $[\\%]$')\n",
    "    ax.xaxis.grid(False)\n",
    "    ax.set_ylim([0.0, 0.2])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for wavelength in [355,532,1064]:\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(11, 7))\n",
    "\n",
    "    pd.pivot_table(all_wavs_configABCD\n",
    "                   [all_wavs_configABCD.wavelength==wavelength],\n",
    "                   values=['MARELoss'],\n",
    "                   columns= ['config'],\n",
    "                   index=['use_bg', 'pow_x2','pow_x3'],\n",
    "                   aggfunc=np.min).\\\n",
    "        plot(kind='bar',ax =ax, title=f'Minimal loss on extended database \\n'+fr'Testing the background contribution - ${wavelength}[\\rm nm]$')\n",
    "    ax.get_yaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "    ax.grid(b=True, which='minor', color='w', linewidth=0.8)\n",
    "    ax.grid(b=True, which='major', color='w', linewidth=1.2)\n",
    "    ax.set_ylabel(r'Relative error $[\\%]$')\n",
    "    ax.xaxis.grid(False)\n",
    "    ax.set_ylim([0.0, 0.2])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 10))\n",
    "\n",
    "pd.pivot_table(all_wavs_configABCD[all_wavs_configABCD.use_power==False][all_wavs_configABCD.note=='extended_db'],\n",
    "               values=['MARELoss'],\n",
    "               columns= ['config'],\n",
    "               index=['wavelength','note'],#'use_bg'],\n",
    "               aggfunc=np.min).\\\n",
    "    plot(kind='bar',ax =ax, title='Minimal loss on the extended database \\n Testing results without power transform')\n",
    "ax.get_yaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "ax.grid(b=True, which='minor', color='w', linewidth=0.8)\n",
    "ax.grid(b=True, which='major', color='w', linewidth=1.2)\n",
    "ax.set_ylabel(r'Relative error $[\\%]$')\n",
    "ax.xaxis.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "lidar",
   "language": "python",
   "display_name": "lidar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}