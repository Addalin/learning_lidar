{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\addalin\\Dropbox\\Lidar\\code\\miscLidar.py:40: MatplotlibDeprecationWarning: Support for setting the 'text.latex.preamble' or 'pgf.preamble' rcParam to a list of strings is deprecated since 3.3 and will be removed two minor releases later; set it to a single string instead.\n",
      "  plt.rcParams['text.latex.preamble'] = [r\"\\usepackage{amsmath}\"]\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "#from netCDF4 import Dataset\n",
    "import matplotlib\n",
    "from datetime import datetime, timedelta, time\n",
    "import glob\n",
    "from generate_atmosphere import LidarProfile,RadiosondeProfile\n",
    "import miscLidar as mscLid\n",
    "from molecular import rayleigh_scattering\n",
    "import global_settings as gs\n",
    "import pandas as pd\n",
    "#import ARLreader as Ar\n",
    "import preprocessing as prep\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Imports\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "'''set day'''\n",
    "day_date = datetime(2017,9,1)\n",
    "\n",
    "'''set station'''\n",
    "haifa_station = gs.station()\n",
    "\n",
    "'''Set paths'''\n",
    "#lidar_parent_folder = 'H:\\data_haifa\\DATA FROM TROPOS\\data\\level1a\\PollyXT_TROPOS'\n",
    "#gdas_parent_folder = 'H:\\data_haifa\\DATA FROM TROPOS\\GDAS\\haifa'\n",
    "lidar_parent_folder = haifa_station.lidar_src_folder\n",
    "haifa_station.gdas1_folder = os.path.join('.','data examples','gdas')\n",
    "haifa_station.gdastxt_folder  = os.path.join('.','data examples','gdas_txt')\n",
    "gdas1_folder,gdas1_paths = prep.get_gdas_paths(haifa_station, day_date,'gdas1')\n",
    "\n",
    "gdastxt_folder, gdastxt_paths = prep.get_gdas_paths(haifa_station, day_date,'txt')\n",
    "\n",
    "print(gdastxt_paths)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "gdastxt_new =[]\n",
    "gdastxt_new = prep.convert_daily_gdas ( day_date , haifa_station )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "['.\\\\data examples\\\\gdas_txt\\\\2017\\\\09\\\\haifa_20170901_00_32.8_35.0.txt',\n '.\\\\data examples\\\\gdas_txt\\\\2017\\\\09\\\\haifa_20170901_03_32.8_35.0.txt',\n '.\\\\data examples\\\\gdas_txt\\\\2017\\\\09\\\\haifa_20170901_06_32.8_35.0.txt',\n '.\\\\data examples\\\\gdas_txt\\\\2017\\\\09\\\\haifa_20170901_09_32.8_35.0.txt',\n '.\\\\data examples\\\\gdas_txt\\\\2017\\\\09\\\\haifa_20170901_12_32.8_35.0.txt',\n '.\\\\data examples\\\\gdas_txt\\\\2017\\\\09\\\\haifa_20170901_15_32.8_35.0.txt',\n '.\\\\data examples\\\\gdas_txt\\\\2017\\\\09\\\\haifa_20170901_18_32.8_35.0.txt',\n '.\\\\data examples\\\\gdas_txt\\\\2017\\\\09\\\\haifa_20170901_21_32.8_35.0.txt',\n '.\\\\data examples\\\\gdas_txt\\\\2017\\\\09\\\\haifa_20170902_00_32.8_35.0.txt',\n '.\\\\data examples\\\\gdas_txt\\\\2017\\\\09\\\\haifa_20170902_03_32.8_35.0.txt',\n '.\\\\data examples\\\\gdas_txt\\\\2017\\\\09\\\\haifa_20170902_06_32.8_35.0.txt',\n '.\\\\data examples\\\\gdas_txt\\\\2017\\\\09\\\\haifa_20170902_09_32.8_35.0.txt',\n '.\\\\data examples\\\\gdas_txt\\\\2017\\\\09\\\\haifa_20170902_12_32.8_35.0.txt',\n '.\\\\data examples\\\\gdas_txt\\\\2017\\\\09\\\\haifa_20170902_15_32.8_35.0.txt',\n '.\\\\data examples\\\\gdas_txt\\\\2017\\\\09\\\\haifa_20170902_18_32.8_35.0.txt',\n '.\\\\data examples\\\\gdas_txt\\\\2017\\\\09\\\\haifa_20170902_21_32.8_35.0.txt']"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_day = day_date + timedelta ( days = 1 )\n",
    "gdastxt_new.extend(prep.convert_daily_gdas ( next_day , haifa_station ))\n",
    "gdastxt_new"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "['.\\\\data examples\\\\gdas_txt\\\\2017\\\\09\\\\haifa_20170902_00_32.8_35.0.txt',\n '.\\\\data examples\\\\gdas_txt\\\\2017\\\\09\\\\haifa_20170902_03_32.8_35.0.txt',\n '.\\\\data examples\\\\gdas_txt\\\\2017\\\\09\\\\haifa_20170902_06_32.8_35.0.txt',\n '.\\\\data examples\\\\gdas_txt\\\\2017\\\\09\\\\haifa_20170902_09_32.8_35.0.txt',\n '.\\\\data examples\\\\gdas_txt\\\\2017\\\\09\\\\haifa_20170902_12_32.8_35.0.txt',\n '.\\\\data examples\\\\gdas_txt\\\\2017\\\\09\\\\haifa_20170902_15_32.8_35.0.txt',\n '.\\\\data examples\\\\gdas_txt\\\\2017\\\\09\\\\haifa_20170902_18_32.8_35.0.txt',\n '.\\\\data examples\\\\gdas_txt\\\\2017\\\\09\\\\haifa_20170902_21_32.8_35.0.txt']"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bsc_paths, profile_paths = prep.load_att_bsc(lidar_parent_folder, day_date)\n",
    "bsc_paths\n",
    "profile_paths"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Load netcdf file of the attenuation backscatter profile (att_bsc.nc)\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "haifa_station = gs.station()\n",
    "#print(haifa_station.__dict__)\n",
    "src_folder = os.path.join(os.getcwd(),'data examples\\gdas')\n",
    "dst_folder = os.path.join(os.getcwd(),'data examples\\gdas_txt')\n",
    "gdas_dst_paths = prep.daily_gdas2txt(day_date, haifa_station.location,\n",
    "                                   haifa_station.lat, haifa_station.lon,\n",
    "                                   src_folder, dst_folder)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Converting gdas files from TROPOS to txt\n"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "'''set parameters'''\n",
    "lambda_um = gs.LAMBDA_um().G\n",
    "haifa_station = gs.station()\n",
    "min_height_km = (1E-3)*(haifa_station.altitude + haifa_station.start_bin_height)\n",
    "top_height_km = (1E-3)*(haifa_station.altitude + haifa_station.end_bin_height)\n",
    "\n",
    "df_sigma, df_beta = prep.generate_daily_molecular_profile(\n",
    "\tgdas_dst_paths,lambda_um,haifa_station.location, haifa_station.lat,\n",
    "\thaifa_station.lon,min_height_km , top_height_km,haifa_station.n_bins)\n",
    "\n",
    "#df_sigma"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Generate daily molecular profiles from the converted files (above)\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-00281cb3f7d3>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfigure\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mdf_beta\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mplot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "df_beta.plot()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Visualizing molecular profiles\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def generate_daily_att_bsc_mol(lambda_um, station, time_res='30S'):\n",
    "\t\"\"\"\t \"\"\"\n",
    "\n",
    "\t'''Load daily gdas profiles and convert to backscatter (beta) and extinction (sigma) profiles'''\n",
    "\tmin_height_km = (station.altitude + station.start_bin_height) * 1E-3\n",
    "\ttop_height_km = (station.altitude + station.end_bin_height) * 1E-3\n",
    "\n",
    "\tdf_sigma, df_beta = prep.generate_daily_molecular_profile(\n",
    "\t\tgdas_dst_paths,lambda_um,station.location, station.lat,\n",
    "\t\tstation.lon,min_height_km , top_height_km,station.n_bins)\n",
    "\n",
    "\t''' Interpolate profiles through 24 hrs'''\n",
    "\tinterp_sigma_df=(df_sigma.T.resample(time_res).interpolate(method='linear')[:-1]).T\n",
    "\tinterp_beta_df=(df_beta.T.resample(time_res).interpolate(method='linear')[:-1]).T\n",
    "\theights = np.linspace(station.altitude + station.start_bin_height,\n",
    "                      station.altitude + station.end_bin_height,\n",
    "                      station.n_bins)\n",
    "\tinterp_sigma_df.index = heights\n",
    "\tinterp_sigma_df.columns.freq = None\n",
    "\tinterp_beta_df.index = heights\n",
    "\tinterp_beta_df.columns.freq = None\n",
    "\n",
    "\t'''Calculate the molecular attenuated backscatter as :  beta_mol * exp(-2*tau_mol)'''\n",
    "\te_tau_df = interp_sigma_df.apply(prep.cal_e_tau_df,0,args=(haifa_station.altitude,),result_type='expand')\n",
    "\tprint ('e_tau ',e_tau_df)\n",
    "\tatt_bsc_mol_df = interp_beta_df.multiply(e_tau_df)\n",
    "\n",
    "\n",
    "\timport xarray as xr\n",
    "\tmol_xr= xr.DataArray(data=[interp_beta_df,interp_sigma_df,att_bsc_mol_df],\n",
    "                     coords=[['beta','sigma','att_bsc_mol'],interp_beta_df.index,interp_beta_df.columns],\n",
    "                     dims = ['profiles','height','time'],\n",
    "                     name='molecular')#,interp_beta_df.index,interp_beta_df.columns )\n",
    "\n",
    "\n",
    "\n",
    "\treturn att_bsc_mol_df,mol_xr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_mol\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gdas_dst_paths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-20-ef2014606ff0>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mlambda_um\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mLAMBDA_um\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mG\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mhaifa_station\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstation\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0mmol_df\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mmol_xr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgenerate_att_bsc_mol\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlambda_um\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhaifa_station\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtime_res\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'30S'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[0mmol_xr\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-19-245972c3f94a>\u001B[0m in \u001B[0;36mgenerate_att_bsc_mol\u001B[1;34m(lambda_um, station, time_res)\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m \tdf_sigma, df_beta = prep.generate_daily_molecular_profile(\n\u001B[1;32m----> 9\u001B[1;33m                 \u001B[0mgdas_dst_paths\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mlambda_um\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mstation\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlocation\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstation\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlat\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     10\u001B[0m \t\tstation.lon,min_height_km , top_height_km,station.n_bins)\n\u001B[0;32m     11\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'gdas_dst_paths' is not defined"
     ]
    }
   ],
   "source": [
    "print('df_mol')\n",
    "lambda_um = gs.LAMBDA_um().G\n",
    "haifa_station = gs.station()\n",
    "mol_df,mol_xr = generate_daily_att_bsc_mol(lambda_um, haifa_station, time_res='30S')\n",
    "mol_xr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cur_df= mol_df\n",
    "x_lims = mdates.date2num([cur_df.columns[0],cur_df.columns[-1]])\n",
    "y_lims = [cur_df.index[0]*1E-3, cur_df.index[-1]*1E-3]\n",
    "extent = [x_lims[0],x_lims[1],y_lims[0],y_lims[1] ]\n",
    "fig, ax = plt.subplots(figsize=(16,15))\n",
    "im = ax.imshow(cur_df, origin='lower',aspect='auto',cmap = 'turbo',\n",
    "               extent=extent)#[0,2779,interp_sigma_df.index[0], interp_sigma_df.index[-1]])\n",
    "\n",
    "ax.set_ylabel('Altitude [km]',fontsize = 24)\n",
    "ax.set_xlabel('Time',fontsize = 24)\n",
    "plt.rc('xtick',labelsize = 18)\n",
    "plt.rc('ytick',labelsize = 18)\n",
    "fig.colorbar(im,ax= ax)\n",
    "ax.xaxis_date()\n",
    "ax.get_xaxis().set_major_locator(mdates.MinuteLocator(interval=120))\n",
    "xfmt = mdates.DateFormatter('%H:%M')\n",
    "ax.xaxis.set_major_formatter(xfmt)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Visualise att_bsc (range corrected molecular signal without p_const)\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: generate daily molecular mol_df - for several days\n",
    "# TODO: validate units of height, speed of light, sigma and beta !!! (km or m)\n",
    "# TODO: define attributes of mol_xr\n",
    "# TODO: create xarray to a daily molecular profile for three channels (UV,G,IR)\n",
    "# TODO: convert from xarray to pytorch\n",
    "# TODO: save xarray as netcd file\n",
    "# TODO: create table of profiles (for the data loader)\n",
    "\n",
    "# TODO: Create samples of 30 min acording to 'profiles' times\n",
    "# for the followings :\n",
    "# X = {lidar measurement (range corrected) molecular (range corrected)}\n",
    "# Y = {lidar const, reference height [min,max]}\n",
    "\n",
    "## AERONET : https://aeronet.gsfc.nasa.gov/cgi-bin/data_display_aod_v3?site=Technion_Haifa_IL&nachal=0&year=2017&month=5&day=19&aero_water=0&level=3&if_day=0&if_err=0&place_code=10&DATA_TYPE=-999&year_or_month=3\n",
    "## it is possible to merge with Terra MODIS or Aqua MODIS -\n",
    "# / TODO: locate the function that does donwload of sunphotometer data to cameranetwork (maybe Shubi knows this)\n",
    "# / TODO: ask about the relevant product from MODIS to our porpose.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% TODOS:\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "lidar",
   "language": "python",
   "display_name": "lidar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}