{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\addalin\\Dropbox\\Lidar\\code\\miscLidar.py:40: MatplotlibDeprecationWarning: Support for setting the 'text.latex.preamble' or 'pgf.preamble' rcParam to a list of strings is deprecated since 3.3 and will be removed two minor releases later; set it to a single string instead.\n",
      "  plt.rcParams['text.latex.preamble'] = [r\"\\usepackage{amsmath}\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": "datetime.time(12, 50, 14, 677984)"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "#from netCDF4 import Dataset\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from datetime import datetime, timedelta, time\n",
    "import glob\n",
    "from generate_atmosphere import LidarProfile,RadiosondeProfile\n",
    "import miscLidar as mscLid\n",
    "from molecular import rayleigh_scattering\n",
    "import global_settings as gs\n",
    "import pandas as pd\n",
    "#import ARLreader as Ar\n",
    "\n",
    "datetime.time(datetime.now())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Imports\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def gdas2radiosonde(src_file,dst_file,\n",
    "        col_names = ['PRES','HGHT','TEMP','UWND',\n",
    "                     'VWND','WWND','RELH','TPOT','WDIR','WSPD']):\n",
    "\t'''\n",
    "\tHelper function that converts a gdas file from TROPOS server, to a simple txt.\n",
    "\tThe resulting file is without any prior info, and resembles the table format\n",
    "\tof a radiosonde file (see class: RadiosondeProfile)\n",
    "\t:param src_file: source file name\n",
    "\t:param dst_file: destination file name\n",
    "\t:param col_names: column names of the final table\n",
    "\t'''\n",
    "\timport pandas as pd\n",
    "\tfrom pandas.api.types import is_numeric_dtype\n",
    "\n",
    "\tdata_src = pd.read_fwf(src_file,skiprows=[0,1,2,3,4,5,6,8],\n",
    "\t                       delimiter=\"\\s+\",skipinitialspace=True).dropna()\n",
    "\t# converting any kind of blanc spaces to zeros\n",
    "\tfor col in data_src.columns:\n",
    "\t\tif not is_numeric_dtype(data_src[col]):\n",
    "\t\t\tdata_src[col]= pd.core.strings.str_strip(data_src[col])\n",
    "\t\t\tdata_src[col]= data_src[col].replace('','0').astype('float64')\n",
    "\tdata_src.columns = col_names\n",
    "\tdata_src.to_csv(dst_file,index=False,sep='\\t',na_rep='\\t')\n",
    "\t# TODO: add warning if failed\n",
    "def extract_date_time(path,format_filename,format_times):\n",
    "\t# Extracting datetime from file name using a formatter string.\n",
    "\t#\n",
    "\t# Usage:\n",
    "\t# create a formatter string: format_filename=  r'-(.*)_(.*)-(.*)-.*.txt'\n",
    "\t# Call the function:        f time_stamp = extract_date_time(soundePath,r'40179_(.*).txt',['%Y%m%d_%H'])\n",
    "\t# Output:\n",
    "\t#       time_stamps - A list of datetime objects\n",
    "\timport re\n",
    "\tfilename = os.path.basename(path)\n",
    "\t#print(filename)\n",
    "\tmatchObj = re.match(format_filename, filename, re.M|re.I)\n",
    "\t# print(matchObj)\n",
    "\ttime_stamps=[]\n",
    "\tfor fmt_time,grp in zip(format_times,matchObj.groups()):\n",
    "\t\ttime_stamps.append(datetime.strptime(grp,fmt_time))\n",
    "\treturn time_stamps\n",
    "def calc_sigma_profile_df(row,lambda_um = 532.0,indx_n= 'sigma'):\n",
    "\t'''\n",
    "\tReturns pd series of extinction profile [1/m] from a radiosonde dataframe containing the\n",
    "\tcolumns:['PRES','TEMPS',RELHS]. The function applies on rows of the radiosonde df.\n",
    "\t:param row: row of radiosonde df\n",
    "\t:param lambda_um: wavelength in [um], e.g, for green lambda_um = 532.0 [um]\n",
    "\t:param indx_n: index name, the column name of the result. The default is 'sigma'\n",
    "\tbut could be useful to get profiles for several hours each have a different index name\n",
    "\t(e.g., datetime object of measuring time of the radiosonde as datetime.datetime(2017, 9, 2, 0, 0))\n",
    "\t:return: pd series of extinction profile [1/m]\n",
    "\t'''\n",
    "\treturn pd.Series([rayleigh_scattering.alpha_rayleigh(wavelength= lambda_um,\n",
    "\t                                       pressure=row['PRES'],\n",
    "\t                                       temperature=row['TEMPS'],\n",
    "\t                                       C=385.0, rh=row['RELHS'])],index=[indx_n])\n",
    "def calc_beta_profile_df(row,lambda_um = 532.0,ind_n= 'beta'):\n",
    "\t'''\n",
    "\tReturns pd series of backscatter profile from a radiosonde dataframe containing the\n",
    "\tcolumns:['PRES','TEMPS',RELHS]. The function applies on rows of the radiosonde df.\n",
    "\t:param row: row of radiosonde df\n",
    "\t:param lambda_um: wavelength in [um], e.g, for green lambda_um = 532.0 [um]\n",
    "\t:param indx_n: index name, the column name of the result. The default is 'beta'\n",
    "\tbut could be useful to get profiles for several hours each have a different index name\n",
    "\t(e.g., datetime object of measuring time of the radiosonde as datetime.datetime(2017, 9, 2, 0, 0))\n",
    "\t:return: pd series of backscatter profile [1/sr*m]\n",
    "\t'''\n",
    "\treturn pd.Series([rayleigh_scattering.beta_pi_rayleigh(wavelength= lambda_um,\n",
    "\t                                       pressure=row['PRES'],\n",
    "\t                                       temperature=row['TEMPS'],\n",
    "\t                                       C=385.0, rh=row['RELHS'])],index=[ind_n])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%  Helper functions\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "'''set day'''\n",
    "\n",
    "day_date = datetime(2017,9,1)\n",
    "\n",
    "'''Set paths to parents folder '''\n",
    "lidar_parent_folder = 'H:\\data_haifa\\DATA FROM TROPOS\\data\\level1a\\PollyXT_TROPOS'\n",
    "gdas_parent_folder = 'H:\\data_haifa\\DATA FROM TROPOS\\GDAS\\haifa'\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "lidar_day_folder = os.path.join(lidar_parent_folder,day_date.strftime(\"%Y\\%m\\%d\"))\n",
    "os.listdir(lidar_day_folder)\n",
    "bsc_pattern = os.path.join(lidar_day_folder,\"*_att_bsc.nc\")\n",
    "bsc_paths = sorted(glob.glob(bsc_pattern))\n",
    "#bsc_paths\n",
    "profile_pattern = os.path.join(lidar_day_folder,\"*[0-9]_profiles.nc\")\n",
    "profile_paths = sorted(glob.glob(profile_pattern))\n",
    "#profile_paths\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Load netcdf file of the attenuation backscatter profile (att_bsc.nc)\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Done conversion src:  C:\\Users\\addalin\\Dropbox\\Lidar\\code\\data examples/gdas\\haifa_20170901_00_32.8_35.0.gdas1 dst:  C:\\Users\\addalin\\Dropbox\\Lidar\\code\\data examples/gdas_txt\\haifa_20170901_00_32.8_35.0.txt\n",
      "\n",
      " Done conversion src:  C:\\Users\\addalin\\Dropbox\\Lidar\\code\\data examples/gdas\\haifa_20170901_03_32.8_35.0.gdas1 dst:  C:\\Users\\addalin\\Dropbox\\Lidar\\code\\data examples/gdas_txt\\haifa_20170901_03_32.8_35.0.txt\n",
      "\n",
      " Done conversion src:  C:\\Users\\addalin\\Dropbox\\Lidar\\code\\data examples/gdas\\haifa_20170901_06_32.8_35.0.gdas1 dst:  C:\\Users\\addalin\\Dropbox\\Lidar\\code\\data examples/gdas_txt\\haifa_20170901_06_32.8_35.0.txt\n",
      "\n",
      " Done conversion src:  C:\\Users\\addalin\\Dropbox\\Lidar\\code\\data examples/gdas\\haifa_20170901_09_32.8_35.0.gdas1 dst:  C:\\Users\\addalin\\Dropbox\\Lidar\\code\\data examples/gdas_txt\\haifa_20170901_09_32.8_35.0.txt\n",
      "\n",
      " Done conversion src:  C:\\Users\\addalin\\Dropbox\\Lidar\\code\\data examples/gdas\\haifa_20170901_12_32.8_35.0.gdas1 dst:  C:\\Users\\addalin\\Dropbox\\Lidar\\code\\data examples/gdas_txt\\haifa_20170901_12_32.8_35.0.txt\n",
      "\n",
      " Done conversion src:  C:\\Users\\addalin\\Dropbox\\Lidar\\code\\data examples/gdas\\haifa_20170901_15_32.8_35.0.gdas1 dst:  C:\\Users\\addalin\\Dropbox\\Lidar\\code\\data examples/gdas_txt\\haifa_20170901_15_32.8_35.0.txt\n",
      "\n",
      " Done conversion src:  C:\\Users\\addalin\\Dropbox\\Lidar\\code\\data examples/gdas\\haifa_20170901_18_32.8_35.0.gdas1 dst:  C:\\Users\\addalin\\Dropbox\\Lidar\\code\\data examples/gdas_txt\\haifa_20170901_18_32.8_35.0.txt\n",
      "\n",
      " Done conversion src:  C:\\Users\\addalin\\Dropbox\\Lidar\\code\\data examples/gdas\\haifa_20170901_21_32.8_35.0.gdas1 dst:  C:\\Users\\addalin\\Dropbox\\Lidar\\code\\data examples/gdas_txt\\haifa_20170901_21_32.8_35.0.txt\n",
      "\n",
      " Done conversion src:  C:\\Users\\addalin\\Dropbox\\Lidar\\code\\data examples/gdas\\haifa_20170902_00_32.8_35.0.gdas1 dst:  C:\\Users\\addalin\\Dropbox\\Lidar\\code\\data examples/gdas_txt\\haifa_20170902_00_32.8_35.0.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": "'gdas_month_folder = os.path.join(gdas_parent_folder, day_date.strftime(\"%Y\\\\%m\"))\\n#print (os.path.exists(gdas_month_folder))\\n\\ngdas_cur_pattern = \\'haifa_{}_*_{}_{}.gdas1\\'.format(day_date.strftime(\\'%Y%m%d\\'),gs.lat,gs.lon)\\ngdas_next = \\'haifa_{}_00_{}_{}.gdas1\\'.format((day_date+timedelta(days=1)).strftime(\\'%Y%m%d\\'),gs.lon,gs.lat)\\ngdas_pattern  = os.path.join(gdas_month_folder,gdas_cur_pattern)\\ngdas_paths = sorted(glob.glob(gdas_pattern))\\ngdas_paths.append(os.path.join(gdas_month_folder,gdas_next))\\n#gdas_file = Ar.fname_from_date(day_date)\\n#print(\\'name of input file \\', gdas_pattern)'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "'''set source gdas files '''\n",
    "# TODO: Add namings and existing path validation (print warnings and errors)\n",
    "src_folder = os.path.join(os.getcwd(),'data examples/gdas')\n",
    "gdas_curd_pattern = 'haifa_{}_*_{}_{}.gdas1'.\\\n",
    "\tformat(day_date.strftime('%Y%m%d'),gs.lat,gs.lon)\n",
    "gdas_nxtd_pattern = 'haifa_{}_00_{}_{}.gdas1'.\\\n",
    "\tformat((day_date+timedelta(days=1)).strftime('%Y%m%d'),gs.lat,gs.lon)\n",
    "gdas_src_paths = sorted(glob.glob(os.path.join(src_folder,gdas_curd_pattern)))\n",
    "gdas_src_paths.append(os.path.join(src_folder,gdas_nxtd_pattern))\n",
    "\n",
    "'''set dest txt files'''\n",
    "dst_folder = os.path.join(os.getcwd(),'data examples/gdas_txt')\n",
    "# TODO: Add validation and indicate if folder already existed or created now (print warnings and errors)\n",
    "Path(dst_folder).mkdir(parents=True, exist_ok=True)\n",
    "gdas_dst_paths = [sub.replace(src_folder, dst_folder).\n",
    "\t                  replace('gdas1','txt') for sub in gdas_src_paths]\n",
    "for (src_file,dst_file) in zip(gdas_src_paths,gdas_dst_paths):\n",
    "\tgdas2radiosonde(src_file,dst_file)\n",
    "\tprint('\\n Done conversion src: ',src_file,'dst: ',dst_file)\n",
    "\t#sanity check\n",
    "\t#data_dst =pd.read_csv(dst_file,delimiter=\"\\s+\")\n",
    "\t#print(data_dst)\n",
    "\n",
    "# TODO : set 'gdas_src_paths' and 'src_folder' according to 'start_date' and 'end_date' -\n",
    "#  for conversion of a big chunk of gdas files. See examples below.\n",
    "# TODO : set 'gdas_dst_paths' in similar way. Such that the folders of gdas and txt files will have same tree\n",
    "#  (or just save it in the same folders?)\n",
    "'''gdas_month_folder = os.path.join(gdas_parent_folder, day_date.strftime(\"%Y\\%m\"))\n",
    "#print (os.path.exists(gdas_month_folder))\n",
    "\n",
    "gdas_cur_pattern = 'haifa_{}_*_{}_{}.gdas1'.format(day_date.strftime('%Y%m%d'),gs.lat,gs.lon)\n",
    "gdas_next = 'haifa_{}_00_{}_{}.gdas1'.format((day_date+timedelta(days=1)).strftime('%Y%m%d'),gs.lon,gs.lat)\n",
    "gdas_pattern  = os.path.join(gdas_month_folder,gdas_cur_pattern)\n",
    "gdas_paths = sorted(glob.glob(gdas_pattern))\n",
    "gdas_paths.append(os.path.join(gdas_month_folder,gdas_next))\n",
    "#gdas_file = Ar.fname_from_date(day_date)\n",
    "#print('name of input file ', gdas_pattern)'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Converting gdas files from TROPOS to txt\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000,) 0.229 22.71466 0.00749771923974657\n"
     ]
    }
   ],
   "source": [
    "'''physical parameters'''\n",
    "lambda_um = gs.LAMBDA_um.G\n",
    "#dr = 7.47e-3       # Height resolution dr~= 7.5e-3[km] (similar to the lidar height resolution)\n",
    "top_height = 22.48566+0.229 # min_height# Top height for interest signals (similar to the top height of the lidar measurement)\n",
    "#heights= np.arange(min_height,top_height,dr)#setting heights for interpolation of gdas/radiosonde inputs\n",
    "h_bins = 3000\n",
    "heights = np.linspace(gs.min_height, top_height,h_bins)\n",
    "\n",
    "print(heights.shape,gs.min_height,top_height, heights[1]-heights[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% GENERATE DAYLY MOLECULAR PROFILE from the converted files (above)\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "df_sigma = pd.DataFrame()\n",
    "df_beta = pd.DataFrame()\n",
    "\n",
    "for dst_file in gdas_dst_paths:\n",
    "\tdf_sonde = RadiosondeProfile(dst_file).get_df_sonde(heights)\n",
    "\t#df_sonde = sondeprofile.get_df_sonde(heights)\n",
    "\ttime = extract_date_time(dst_file,r'haifa_(.*)_32.8_35.0.txt',['%Y%m%d_%H'])[0]\n",
    "\t'''Calculating molecular profiles from temperature and pressure'''\n",
    "\tres = df_sonde.apply(calc_sigma_profile_df,axis = 1,args=(lambda_um,time,),result_type='expand').astype('float64')\n",
    "\tdf_sigma[res.columns]=res\n",
    "\tres = df_sonde.apply(calc_beta_profile_df,axis = 1,args=(lambda_um,time,),result_type='expand').astype('float64')\n",
    "\tdf_beta[res.columns]=res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dict expected at most 1 argument, got 12",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-21-55de650c48f5>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m stations = {\n\u001B[1;32m----> 2\u001B[1;33m \t'haifa' : dict(\n\u001B[0m\u001B[0;32m      3\u001B[0m                 \u001B[1;34m'lon'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m35.0\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m                 \u001B[1;34m'lat'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m32.8\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m                 \u001B[1;34m'altitude'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m229\u001B[0m\u001B[1;33m,\u001B[0m                \u001B[1;31m# [m] The Lidar's altitude   ( above sea level, see 'altitude' in ' *_att_bsc.nc)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: dict expected at most 1 argument, got 12"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import preprocessing as prep\n",
    "\n",
    "df_sigma, df_beta = prep.generate_daily_molecular_profile(gdas_dst_paths,lambda_um,gs.location,\n",
    "                                                             gs.lat, gs.lon,gs.min_height , top_height,h_bins)\n",
    "\n",
    "'''Visualize molecular profiles'''\n",
    "plt.figure()\n",
    "df_beta.plot()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Visualizing profiles\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "      2017-09-01 00:00:00  2017-09-01 03:00:00  2017-09-01 06:00:00  \\\n0            1.229954e-05         1.229392e-05         1.226841e-05   \n1            1.229210e-05         1.228634e-05         1.226103e-05   \n2            1.228467e-05         1.227876e-05         1.225365e-05   \n3            1.227723e-05         1.227118e-05         1.224627e-05   \n4            1.226978e-05         1.226360e-05         1.223888e-05   \n...                   ...                  ...                  ...   \n2995         7.140383e-07         7.148859e-07         7.163339e-07   \n2996         7.133059e-07         7.141544e-07         7.156022e-07   \n2997         7.125735e-07         7.134231e-07         7.148705e-07   \n2998         7.118413e-07         7.126919e-07         7.141390e-07   \n2999         7.111092e-07         7.119608e-07         7.134075e-07   \n\n      2017-09-01 09:00:00  2017-09-01 12:00:00  2017-09-01 15:00:00  \\\n0            1.224329e-05         1.223423e-05         1.221993e-05   \n1            1.223623e-05         1.222680e-05         1.221245e-05   \n2            1.222917e-05         1.221936e-05         1.220495e-05   \n3            1.222211e-05         1.221191e-05         1.219746e-05   \n4            1.221504e-05         1.220447e-05         1.218997e-05   \n...                   ...                  ...                  ...   \n2995         7.162655e-07         7.142611e-07         7.143396e-07   \n2996         7.155326e-07         7.135299e-07         7.136088e-07   \n2997         7.147999e-07         7.127988e-07         7.128780e-07   \n2998         7.140672e-07         7.120678e-07         7.121474e-07   \n2999         7.133347e-07         7.113369e-07         7.114169e-07   \n\n      2017-09-01 18:00:00  2017-09-01 21:00:00  2017-09-02 00:00:00  \n0            1.221980e-05         1.222868e-05         1.223681e-05  \n1            1.221271e-05         1.222162e-05         1.222945e-05  \n2            1.220562e-05         1.221456e-05         1.222208e-05  \n3            1.219852e-05         1.220749e-05         1.221471e-05  \n4            1.219142e-05         1.220042e-05         1.220734e-05  \n...                   ...                  ...                  ...  \n2995         7.141116e-07         7.141563e-07         7.125950e-07  \n2996         7.133797e-07         7.134222e-07         7.118578e-07  \n2997         7.126478e-07         7.126882e-07         7.111206e-07  \n2998         7.119161e-07         7.119543e-07         7.103836e-07  \n2999         7.111845e-07         7.112205e-07         7.096467e-07  \n\n[3000 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>2017-09-01 00:00:00</th>\n      <th>2017-09-01 03:00:00</th>\n      <th>2017-09-01 06:00:00</th>\n      <th>2017-09-01 09:00:00</th>\n      <th>2017-09-01 12:00:00</th>\n      <th>2017-09-01 15:00:00</th>\n      <th>2017-09-01 18:00:00</th>\n      <th>2017-09-01 21:00:00</th>\n      <th>2017-09-02 00:00:00</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.229954e-05</td>\n      <td>1.229392e-05</td>\n      <td>1.226841e-05</td>\n      <td>1.224329e-05</td>\n      <td>1.223423e-05</td>\n      <td>1.221993e-05</td>\n      <td>1.221980e-05</td>\n      <td>1.222868e-05</td>\n      <td>1.223681e-05</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.229210e-05</td>\n      <td>1.228634e-05</td>\n      <td>1.226103e-05</td>\n      <td>1.223623e-05</td>\n      <td>1.222680e-05</td>\n      <td>1.221245e-05</td>\n      <td>1.221271e-05</td>\n      <td>1.222162e-05</td>\n      <td>1.222945e-05</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.228467e-05</td>\n      <td>1.227876e-05</td>\n      <td>1.225365e-05</td>\n      <td>1.222917e-05</td>\n      <td>1.221936e-05</td>\n      <td>1.220495e-05</td>\n      <td>1.220562e-05</td>\n      <td>1.221456e-05</td>\n      <td>1.222208e-05</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.227723e-05</td>\n      <td>1.227118e-05</td>\n      <td>1.224627e-05</td>\n      <td>1.222211e-05</td>\n      <td>1.221191e-05</td>\n      <td>1.219746e-05</td>\n      <td>1.219852e-05</td>\n      <td>1.220749e-05</td>\n      <td>1.221471e-05</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.226978e-05</td>\n      <td>1.226360e-05</td>\n      <td>1.223888e-05</td>\n      <td>1.221504e-05</td>\n      <td>1.220447e-05</td>\n      <td>1.218997e-05</td>\n      <td>1.219142e-05</td>\n      <td>1.220042e-05</td>\n      <td>1.220734e-05</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2995</th>\n      <td>7.140383e-07</td>\n      <td>7.148859e-07</td>\n      <td>7.163339e-07</td>\n      <td>7.162655e-07</td>\n      <td>7.142611e-07</td>\n      <td>7.143396e-07</td>\n      <td>7.141116e-07</td>\n      <td>7.141563e-07</td>\n      <td>7.125950e-07</td>\n    </tr>\n    <tr>\n      <th>2996</th>\n      <td>7.133059e-07</td>\n      <td>7.141544e-07</td>\n      <td>7.156022e-07</td>\n      <td>7.155326e-07</td>\n      <td>7.135299e-07</td>\n      <td>7.136088e-07</td>\n      <td>7.133797e-07</td>\n      <td>7.134222e-07</td>\n      <td>7.118578e-07</td>\n    </tr>\n    <tr>\n      <th>2997</th>\n      <td>7.125735e-07</td>\n      <td>7.134231e-07</td>\n      <td>7.148705e-07</td>\n      <td>7.147999e-07</td>\n      <td>7.127988e-07</td>\n      <td>7.128780e-07</td>\n      <td>7.126478e-07</td>\n      <td>7.126882e-07</td>\n      <td>7.111206e-07</td>\n    </tr>\n    <tr>\n      <th>2998</th>\n      <td>7.118413e-07</td>\n      <td>7.126919e-07</td>\n      <td>7.141390e-07</td>\n      <td>7.140672e-07</td>\n      <td>7.120678e-07</td>\n      <td>7.121474e-07</td>\n      <td>7.119161e-07</td>\n      <td>7.119543e-07</td>\n      <td>7.103836e-07</td>\n    </tr>\n    <tr>\n      <th>2999</th>\n      <td>7.111092e-07</td>\n      <td>7.119608e-07</td>\n      <td>7.134075e-07</td>\n      <td>7.133347e-07</td>\n      <td>7.113369e-07</td>\n      <td>7.114169e-07</td>\n      <td>7.111845e-07</td>\n      <td>7.112205e-07</td>\n      <td>7.096467e-07</td>\n    </tr>\n  </tbody>\n</table>\n<p>3000 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sigma"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nvis_molecular = True\\nstime = extract_date_time(dst_file,r\\'haifa_(.*)_32.8_35.0.txt\\',[\\'%Y%m%d_%H\\'])[0].strftime(\\'%Y/%m/%d %H:%M\\')\\n\\nif vis_molecular:\\n    lData  = {\\'x\\':[heights],\\'y\\':[sigma_mol],\\'lableX\\': \\'Heights [km]\\',\\n              \\'lableY\\': r\"$\\x08oldsymbol\\\\sigma\\\\quad[\\rm 1/m]$\",\\n              \\'stitle\\':r\\'$\\x08oldsymbol\\\\sigma_{{\\rm mol}}^{{\\\\lambda={0:.0f}}}$\\'.format(lambda_um)}\\n    rData  = {\\'x\\':[heights],\\'y\\':[beta_mol],\\'lableX\\': \\'Heights [km]\\',\\n              \\'lableY\\': r\\'$\\x08oldsymbol\\x08eta\\\\quad[\\rm{{1}/m \\\\cdot {sr}]}$\\',\\n              \\'stitle\\':r\\'$\\x08oldsymbol\\x08eta_{{\\rm mol}}^{{\\\\lambda={0:.0f}}}$\\'.format(lambda_um)}\\n    stitle= r\\'Molecular profiles {}\\'.format(stime)\\n    [fig, axes] = mscLid.visCurve(lData,rData,stitle)\\n    plt.show()\\t'"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: adjust the func  mscLid.visCurve (used bellow) to signals in the dataframe (instead of showing a single profile , show all of them with the relevant time)\n",
    "'''\n",
    "vis_molecular = True\n",
    "stime = extract_date_time(dst_file,r'haifa_(.*)_32.8_35.0.txt',['%Y%m%d_%H'])[0].strftime('%Y/%m/%d %H:%M')\n",
    "\n",
    "if vis_molecular:\n",
    "    lData  = {'x':[heights],'y':[sigma_mol],'lableX': 'Heights [km]',\n",
    "              'lableY': r\"$\\boldsymbol\\sigma\\quad[\\rm 1/m]$\",\n",
    "              'stitle':r'$\\boldsymbol\\sigma_{{\\rm mol}}^{{\\lambda={0:.0f}}}$'.format(lambda_um)}\n",
    "    rData  = {'x':[heights],'y':[beta_mol],'lableX': 'Heights [km]',\n",
    "              'lableY': r'$\\boldsymbol\\beta\\quad[\\rm{{1}/m \\cdot {sr}]}$',\n",
    "              'stitle':r'$\\boldsymbol\\beta_{{\\rm mol}}^{{\\lambda={0:.0f}}}$'.format(lambda_um)}\n",
    "    stitle= r'Molecular profiles {}'.format(stime)\n",
    "    [fig, axes] = mscLid.visCurve(lData,rData,stitle)\n",
    "    plt.show()\t'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "'@ https://machinelearningmastery.com/resample-interpolate-time-series-data-python/\\n\\ninstead of append, load the profiles to dataframe and then create an image.\\ntreat every row of the dataframe as a time series. so the interpolation is done per row.\\nfrom 00:00,03:00,06:00,09:00,12:00,15:00,18:00,21:00,24:00 to 00:00-24:00 with intervals of 30 sec'"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: check 2D interpolation in transformation (see link below)\n",
    "'''@ https://machinelearningmastery.com/resample-interpolate-time-series-data-python/\n",
    "\n",
    "instead of append, load the profiles to dataframe and then create an image.\n",
    "treat every row of the dataframe as a time series. so the interpolation is done per row.\n",
    "from 00:00,03:00,06:00,09:00,12:00,15:00,18:00,21:00,24:00 to 00:00-24:00 with intervals of 30 sec'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Interpolate 24hr profiles to dataframe\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "' Interpolate on molecular profiles on a 2D grid 00:00-23:59 '"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' read radiosonde at 00:00 and 12:00 and 00:00 (of the day after)'''\n",
    "## radiosonde download and analysis from cameranetwork\n",
    "\n",
    "''' read gdas data for 00:00, 03:00, 06:00, 09:00 ,12:00, 15:00 , 18:00 ,21:00, 24:00'''\n",
    "## use: https://github.com/martin-rdz/ARLreader\n",
    "\n",
    "\n",
    "## AERONET : https://aeronet.gsfc.nasa.gov/cgi-bin/data_display_aod_v3?site=Technion_Haifa_IL&nachal=0&year=2017&month=5&day=19&aero_water=0&level=3&if_day=0&if_err=0&place_code=10&DATA_TYPE=-999&year_or_month=3\n",
    "## it is possible to merge with Terra MODIS or Aqua MODIS -\n",
    "# / TODO: locate the function that does donwload of sunphotometer data to cameranetwork (maybe Shubi knows this)\n",
    "# / TODO: ask about the relevant product from MODIS to our porpose.\n",
    "''' Interpolate on molecular profiles on a 2D grid 00:00-23:59 '''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# for the followings :\n",
    "# X = {lidar measurement (range corrected) molecular (range corrected)}\n",
    "# Y = {lidar const, reference height [min,max]}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Create samples of 30 min acording to 'profiles' times\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-env-.conda-lidar-py",
   "language": "python",
   "display_name": "Python [conda env:.conda-lidar] *"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}