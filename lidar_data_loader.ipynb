{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "datetime.time(19, 34, 12, 560320)"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "#from netCDF4 import Dataset\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from datetime import datetime, timedelta, time\n",
    "import glob\n",
    "from generate_atmosphere import LidarProfile,RadiosondeProfile\n",
    "import miscLidar as mscLid\n",
    "from molecular import rayleigh_scattering\n",
    "import global_settings as gs\n",
    "import pandas as pd\n",
    "#import ARLreader as Ar\n",
    "\n",
    "datetime.time(datetime.now())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Imports\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "def gdas2radiosonde(src_file,dst_file,\n",
    "        col_names = ['PRES','HGHT','TEMP','UWND',\n",
    "                     'VWND','WWND','RELH','TPOT','WDIR','WSPD']):\n",
    "\t'''\n",
    "\tHelper function that converts a gdas file from TROPOS server, to a simple txt.\n",
    "\tThe resulting file is without any prior info, and resembles the table format\n",
    "\tof a radiosonde file (see class: RadiosondeProfile)\n",
    "\t:param src_file: source file name\n",
    "\t:param dst_file: destination file name\n",
    "\t:param col_names: column names of the final table\n",
    "\t'''\n",
    "\timport pandas as pd\n",
    "\tfrom pandas.api.types import is_numeric_dtype\n",
    "\n",
    "\tdata_src = pd.read_fwf(src_file,skiprows=[0,1,2,3,4,5,6,8],\n",
    "\t                       delimiter=\"\\s+\",skipinitialspace=True).dropna()\n",
    "\t# converting any kind of blanc spaces to zeros\n",
    "\tfor col in data_src.columns:\n",
    "\t\tif not is_numeric_dtype(data_src[col]):\n",
    "\t\t\tdata_src[col]= pd.core.strings.str_strip(data_src[col])\n",
    "\t\t\tdata_src[col]= data_src[col].replace('','0').astype('float64')\n",
    "\tdata_src.columns = col_names\n",
    "\tdata_src.to_csv(dst_file,index=False,sep='\\t',na_rep='\\t')\n",
    "\t# TODO: add warning if failed\n",
    "def extract_date_time(path,format_filename,format_times):\n",
    "\t# Extracting datetime from file name using a formatter string.\n",
    "\t#\n",
    "\t# Usage:\n",
    "\t# create a formatter string: format_filename=  r'-(.*)_(.*)-(.*)-.*.txt'\n",
    "\t# Call the function:        f time_stamp = extract_date_time(soundePath,r'40179_(.*).txt',['%Y%m%d_%H'])\n",
    "\t# Output:\n",
    "\t#       time_stamps - A list of datetime objects\n",
    "\timport re\n",
    "\tfilename = os.path.basename(path)\n",
    "\t#print(filename)\n",
    "\tmatchObj = re.match(format_filename, filename, re.M|re.I)\n",
    "\t# print(matchObj)\n",
    "\ttime_stamps=[]\n",
    "\tfor fmt_time,grp in zip(format_times,matchObj.groups()):\n",
    "\t\ttime_stamps.append(datetime.strptime(grp,fmt_time))\n",
    "\treturn time_stamps\n",
    "def calc_sigma_profile_df(row,lambda_um = 532.0,indx_n= 'sigma'):\n",
    "\t'''\n",
    "\tReturns pd series of extinction profile [1/m] from a radiosonde dataframe containing the\n",
    "\tcolumns:['PRES','TEMPS',RELHS]. The function applies on rows of the radiosonde df.\n",
    "\t:param row: row of radiosonde df\n",
    "\t:param lambda_um: wavelength in [um], e.g, for green lambda_um = 532.0 [um]\n",
    "\t:param indx_n: index name, the column name of the result. The default is 'sigma'\n",
    "\tbut could be useful to get profiles for several hours each have a different index name\n",
    "\t(e.g., datetime object of measuring time of the radiosonde as datetime.datetime(2017, 9, 2, 0, 0))\n",
    "\t:return: pd series of extinction profile [1/m]\n",
    "\t'''\n",
    "\treturn pd.Series([rayleigh_scattering.alpha_rayleigh(wavelength= lambda_um,\n",
    "\t                                       pressure=row['PRES'],\n",
    "\t                                       temperature=row['TEMPS'],\n",
    "\t                                       C=385.0, rh=row['RELHS'])],index=[indx_n])\n",
    "def calc_beta_profile_df(row,lambda_um = 532.0,ind_n= 'beta'):\n",
    "\t'''\n",
    "\tReturns pd series of backscatter profile from a radiosonde dataframe containing the\n",
    "\tcolumns:['PRES','TEMPS',RELHS]. The function applies on rows of the radiosonde df.\n",
    "\t:param row: row of radiosonde df\n",
    "\t:param lambda_um: wavelength in [um], e.g, for green lambda_um = 532.0 [um]\n",
    "\t:param indx_n: index name, the column name of the result. The default is 'beta'\n",
    "\tbut could be useful to get profiles for several hours each have a different index name\n",
    "\t(e.g., datetime object of measuring time of the radiosonde as datetime.datetime(2017, 9, 2, 0, 0))\n",
    "\t:return: pd series of backscatter profile [1/sr*m]\n",
    "\t'''\n",
    "\treturn pd.Series([rayleigh_scattering.beta_pi_rayleigh(wavelength= lambda_um,\n",
    "\t                                       pressure=row['PRES'],\n",
    "\t                                       temperature=row['TEMPS'],\n",
    "\t                                       C=385.0, rh=row['RELHS'])],index=[ind_n])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%  Helper functions\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "'''set day'''\n",
    "\n",
    "day_date = datetime(2017,9,1)\n",
    "\n",
    "'''Set paths to parents folder '''\n",
    "lidar_parent_folder = 'H:\\data_haifa\\DATA FROM TROPOS\\data\\level1a\\PollyXT_TROPOS'\n",
    "gdas_parent_folder = 'H:\\data_haifa\\DATA FROM TROPOS\\GDAS\\haifa'\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "lidar_day_folder = os.path.join(lidar_parent_folder,day_date.strftime(\"%Y\\%m\\%d\"))\n",
    "os.listdir(lidar_day_folder)\n",
    "bsc_pattern = os.path.join(lidar_day_folder,\"*_att_bsc.nc\")\n",
    "bsc_paths = sorted(glob.glob(bsc_pattern))\n",
    "#bsc_paths\n",
    "profile_pattern = os.path.join(lidar_day_folder,\"*[0-9]_profiles.nc\")\n",
    "profile_paths = sorted(glob.glob(profile_pattern))\n",
    "#profile_paths\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Load netcdf file of the attenuation backscatter profile (att_bsc.nc)\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__module__': 'global_settings', 'location': 'haifa', 'lon': 35.0, 'lat': 32.8, 'altitude': 229, 'start_bin_height': 78.75, 'end_bin_height': 22485.66015, 'n_bins': 3000, '__dict__': <attribute '__dict__' of 'station' objects>, '__weakref__': <attribute '__weakref__' of 'station' objects>, '__doc__': 'station()', '__dataclass_params__': _DataclassParams(init=True,repr=True,eq=True,order=False,unsafe_hash=False,frozen=False), '__dataclass_fields__': {}, '__init__': <function __create_fn__.<locals>.__init__ at 0x0000026C784F2040>, '__repr__': <function __create_fn__.<locals>.__repr__ at 0x0000026C784F1F70>, '__eq__': <function __create_fn__.<locals>.__eq__ at 0x0000026C784F2280>, '__hash__': None}\n"
     ]
    },
    {
     "data": {
      "text/plain": "'gdas_month_folder = os.path.join(gdas_parent_folder, day_date.strftime(\"%Y\\\\%m\"))\\n#print (os.path.exists(gdas_month_folder))\\n\\ngdas_cur_pattern = \\'haifa_{}_*_{}_{}.gdas1\\'.format(day_date.strftime(\\'%Y%m%d\\'),gs.lat,gs.lon)\\ngdas_next = \\'haifa_{}_00_{}_{}.gdas1\\'.format((day_date+timedelta(days=1)).strftime(\\'%Y%m%d\\'),gs.lon,gs.lat)\\ngdas_pattern  = os.path.join(gdas_month_folder,gdas_cur_pattern)\\ngdas_paths = sorted(glob.glob(gdas_pattern))\\ngdas_paths.append(os.path.join(gdas_month_folder,gdas_next))\\n#gdas_file = Ar.fname_from_date(day_date)\\n#print(\\'name of input file \\', gdas_pattern)'"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "haifa_station = gs.station\n",
    "print(haifa_station.__dict__)\n",
    "\n",
    "\n",
    "'''set source gdas files '''\n",
    "# TODO: Add namings and existing path validation (print warnings and errors)\n",
    "src_folder = os.path.join(os.getcwd(),'data examples/gdas')\n",
    "gdas_curd_pattern = 'haifa_{}_*_{}_{}.gdas1'.\\\n",
    "\tformat(day_date.strftime('%Y%m%d'),haifa_station.lat,haifa_station.lon)\n",
    "gdas_nxtd_pattern = 'haifa_{}_00_{}_{}.gdas1'.\\\n",
    "\tformat((day_date+timedelta(days=1)).strftime('%Y%m%d'),haifa_station.lat,haifa_station.lon)\n",
    "gdas_src_paths = sorted(glob.glob(os.path.join(src_folder,gdas_curd_pattern)))\n",
    "gdas_src_paths.append(os.path.join(src_folder,gdas_nxtd_pattern))\n",
    "\n",
    "'''set dest txt files'''\n",
    "dst_folder = os.path.join(os.getcwd(),'/data examples/gdas_txt')\n",
    "# TODO: Add validation and indicate if folder already existed or created now (print warnings and errors)\n",
    "Path(dst_folder).mkdir(parents=True, exist_ok=True)\n",
    "gdas_dst_paths = [sub.replace(src_folder, dst_folder).\n",
    "\t                  replace('gdas1','txt') for sub in gdas_src_paths]\n",
    "for (src_file,dst_file) in zip(gdas_src_paths,gdas_dst_paths):\n",
    "\tgdas2radiosonde(src_file,dst_file)\n",
    "\t# print('\\n Done conversion src: ',src_file,'dst: ',dst_file)\n",
    "\t#sanity check\n",
    "\t#data_dst =pd.read_csv(dst_file,delimiter=\"\\s+\")\n",
    "\t#print(data_dst)\n",
    "\n",
    "# TODO : set 'gdas_src_paths' and 'src_folder' according to 'start_date' and 'end_date' -\n",
    "#  for conversion of a big chunk of gdas files. See examples below.\n",
    "# TODO : set 'gdas_dst_paths' in similar way. Such that the folders of gdas and txt files will have same tree\n",
    "#  (or just save it in the same folders?)\n",
    "'''gdas_month_folder = os.path.join(gdas_parent_folder, day_date.strftime(\"%Y\\%m\"))\n",
    "#print (os.path.exists(gdas_month_folder))\n",
    "\n",
    "gdas_cur_pattern = 'haifa_{}_*_{}_{}.gdas1'.format(day_date.strftime('%Y%m%d'),gs.lat,gs.lon)\n",
    "gdas_next = 'haifa_{}_00_{}_{}.gdas1'.format((day_date+timedelta(days=1)).strftime('%Y%m%d'),gs.lon,gs.lat)\n",
    "gdas_pattern  = os.path.join(gdas_month_folder,gdas_cur_pattern)\n",
    "gdas_paths = sorted(glob.glob(gdas_pattern))\n",
    "gdas_paths.append(os.path.join(gdas_month_folder,gdas_next))\n",
    "#gdas_file = Ar.fname_from_date(day_date)\n",
    "#print('name of input file ', gdas_pattern)'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Converting gdas files from TROPOS to txt\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000,) 307.75 22714.66015 7.471460536845598\n"
     ]
    }
   ],
   "source": [
    "'''set parameters'''\n",
    "lambda_um = gs.LAMBDA_um.G\n",
    "location = haifa_station.location\n",
    "min_height = haifa_station.altitude + haifa_station.start_bin_height\n",
    "top_height = haifa_station.altitude + haifa_station.end_bin_height\n",
    "#dr = 7.47e-3       # Height resolution dr~= 7.5e-3[km] (similar to the lidar height resolution)\n",
    "heights = np.linspace(min_height, top_height,haifa_station.n_bins)\n",
    "\n",
    "print(heights.shape,min_height,top_height, heights[1]-heights[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% GENERATE DAYLY MOLECULAR PROFILE from the converted files (above)\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "df_sigma = pd.DataFrame()\n",
    "df_beta = pd.DataFrame()\n",
    "\n",
    "for dst_file in gdas_dst_paths:\n",
    "\tdf_sonde = RadiosondeProfile(dst_file).get_df_sonde(heights)\n",
    "\t#df_sonde = sondeprofile.get_df_sonde(heights)\n",
    "\ttime = extract_date_time(dst_file,r'haifa_(.*)_32.8_35.0.txt',['%Y%m%d_%H'])[0]\n",
    "\t'''Calculating molecular profiles from temperature and pressure'''\n",
    "\tres = df_sonde.apply(calc_sigma_profile_df,axis = 1,args=(lambda_um,time,),result_type='expand').astype('float64')\n",
    "\tdf_sigma[res.columns]=res\n",
    "\tres = df_sonde.apply(calc_beta_profile_df,axis = 1,args=(lambda_um,time,),result_type='expand').astype('float64')\n",
    "\tdf_beta[res.columns]=res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'global_settings' has no attribute 'min_height'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-49-7b421b19c6ba>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m df_sigma, df_beta = prep.generate_daily_molecular_profile(\n\u001B[0;32m      4\u001B[0m         \u001B[0mgdas_dst_paths\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mlambda_um\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mhaifa_station\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlocation\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhaifa_station\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlat\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \thaifa_station.lon,gs.min_height , top_height,haifa_station.n_bins)\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;34m'''Visualize molecular profiles'''\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'global_settings' has no attribute 'min_height'"
     ]
    }
   ],
   "source": [
    "import preprocessing as prep\n",
    "\n",
    "df_sigma, df_beta = prep.generate_daily_molecular_profile(\n",
    "\tgdas_dst_paths,lambda_um,haifa_station.location, haifa_station.lat,\n",
    "\thaifa_station.lon,gs.min_height , top_height,haifa_station.n_bins)\n",
    "\n",
    "'''Visualize molecular profiles'''\n",
    "plt.figure()\n",
    "df_beta.plot()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Visualizing profiles\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_sigma"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: adjust the func  mscLid.visCurve (used bellow) to signals in the dataframe (instead of showing a single profile , show all of them with the relevant time)\n",
    "'''\n",
    "vis_molecular = True\n",
    "stime = extract_date_time(dst_file,r'haifa_(.*)_32.8_35.0.txt',['%Y%m%d_%H'])[0].strftime('%Y/%m/%d %H:%M')\n",
    "\n",
    "if vis_molecular:\n",
    "    lData  = {'x':[heights],'y':[sigma_mol],'lableX': 'Heights [km]',\n",
    "              'lableY': r\"$\\boldsymbol\\sigma\\quad[\\rm 1/m]$\",\n",
    "              'stitle':r'$\\boldsymbol\\sigma_{{\\rm mol}}^{{\\lambda={0:.0f}}}$'.format(lambda_um)}\n",
    "    rData  = {'x':[heights],'y':[beta_mol],'lableX': 'Heights [km]',\n",
    "              'lableY': r'$\\boldsymbol\\beta\\quad[\\rm{{1}/m \\cdot {sr}]}$',\n",
    "              'stitle':r'$\\boldsymbol\\beta_{{\\rm mol}}^{{\\lambda={0:.0f}}}$'.format(lambda_um)}\n",
    "    stitle= r'Molecular profiles {}'.format(stime)\n",
    "    [fig, axes] = mscLid.visCurve(lData,rData,stitle)\n",
    "    plt.show()\t'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: check 2D interpolation in transformation (see link below)\n",
    "'''@ https://machinelearningmastery.com/resample-interpolate-time-series-data-python/\n",
    "\n",
    "instead of append, load the profiles to dataframe and then create an image.\n",
    "treat every row of the dataframe as a time series. so the interpolation is done per row.\n",
    "from 00:00,03:00,06:00,09:00,12:00,15:00,18:00,21:00,24:00 to 00:00-24:00 with intervals of 30 sec'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Interpolate 24hr profiles to dataframe\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "''' read radiosonde at 00:00 and 12:00 and 00:00 (of the day after)'''\n",
    "## radiosonde download and analysis from cameranetwork\n",
    "\n",
    "''' read gdas data for 00:00, 03:00, 06:00, 09:00 ,12:00, 15:00 , 18:00 ,21:00, 24:00'''\n",
    "## use: https://github.com/martin-rdz/ARLreader\n",
    "\n",
    "\n",
    "## AERONET : https://aeronet.gsfc.nasa.gov/cgi-bin/data_display_aod_v3?site=Technion_Haifa_IL&nachal=0&year=2017&month=5&day=19&aero_water=0&level=3&if_day=0&if_err=0&place_code=10&DATA_TYPE=-999&year_or_month=3\n",
    "## it is possible to merge with Terra MODIS or Aqua MODIS -\n",
    "# / TODO: locate the function that does donwload of sunphotometer data to cameranetwork (maybe Shubi knows this)\n",
    "# / TODO: ask about the relevant product from MODIS to our porpose.\n",
    "''' Interpolate on molecular profiles on a 2D grid 00:00-23:59 '''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for the followings :\n",
    "# X = {lidar measurement (range corrected) molecular (range corrected)}\n",
    "# Y = {lidar const, reference height [min,max]}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Create samples of 30 min acording to 'profiles' times\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-env-.conda-lidar-py",
   "language": "python",
   "display_name": "Python [conda env:.conda-lidar] *"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}